{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:39:34.906401Z",
     "start_time": "2021-05-10T20:39:27.251009Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaCpEWhEWXH8",
    "outputId": "051abe39-1944-4ac0-ca34-f6c8e9837adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: coral_pytorch in c:\\users\\rodri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rodri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from coral_pytorch) (39.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\rodri\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import axes3d  \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "# from EDA_helper import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "!pip install coral_pytorch\n",
    "import coral_pytorch as coral\n",
    "from coral_pytorch.layers import CoralLayer\n",
    "from coral_pytorch.dataset import levels_from_labelbatch\n",
    "from coral_pytorch.losses import coral_loss\n",
    "from coral_pytorch.dataset import proba_to_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECOMMENDED: Run Neural_nets_cuda.ipynb on Google Colab using GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:39:52.908433Z",
     "start_time": "2021-05-10T20:39:52.826307Z"
    },
    "cellView": "form",
    "code_folding": [
     0
    ],
    "id": "PQQz6sBpjAAJ"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "def format_df(figs, ratings, to_drop = []):\n",
    "    \"\"\"\n",
    "    figs: Pandas df, features\n",
    "    ratings: Pandas df, labels\n",
    "    to_drop: list, cols to remove\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "#     print(len(ratings[\"Ticker Symbol\"].unique()))\n",
    "    ratings1 = ratings[ratings['S&P Domestic Long Term Issuer Credit Rating'].notna()]\n",
    "    ratings1 = ratings1[['Global Company Key','S&P Domestic Long Term Issuer Credit Rating', 'Data Date',\n",
    "                        'Ticker Symbol']]\n",
    "\n",
    "    print(\"Unique Companies in Ratings: \", len(ratings1[\"Ticker Symbol\"].unique()))\n",
    "    # print(\"Unique Companies in Features: \", len(figs[\"Ticker Symbol\"].unique()))\n",
    "\n",
    "    ## WE DON'T USE THIS\n",
    "    if len(to_drop) == 0:\n",
    "        figs_1 = figs.drop(list(figs.columns[[2, 3,4,11,12, 14, 16, 18, 20, 21, 23, 26, 30, 33, 35, 36, 37, 38]]), axis=1).dropna()\n",
    "    else:\n",
    "        # print(ratings1.shape, figs.shape)\n",
    "        figs_1 = figs.drop(to_drop, axis=1).dropna()\n",
    "        # print(ratings1.shape, figs_1.shape)\n",
    "    print(\"Unique Companies in Features: \", len(figs_1[\"Ticker Symbol\"].unique()))\n",
    "\n",
    "    # lst3 = [value for value in ratings1[\"Ticker Symbol\"].unique() if value in figs_1[\"Ticker Symbol\"].unique()]\n",
    "\n",
    "\n",
    "    companies = ratings1[\"Ticker Symbol\"].unique()\n",
    "    # companies\n",
    "    # quarts = ['1231', '0331', '0630', '0930']\n",
    "    # figs_1 = figs_1.loc[figs_1['Ticker Symbol'].isin(companies)]\n",
    "    print(\"changed\")\n",
    "    figs_1['Data Date'] = figs_1['Data Date'].astype(str)\n",
    "    ratings1['Data Date'] = ratings1['Data Date'].astype(str)\n",
    "    # ratings1 = ratings1.loc[ratings1['Data Date'].str[-4:].isin(quarts)]\n",
    "    return figs_1, ratings1\n",
    "\n",
    "\n",
    "def join_numerical(figs_1, ratings1, numerical=[], ind_to_keep=[], years=[]):\n",
    "    \"\"\"\n",
    "    in\n",
    "    figs_1: Pandas df, features\n",
    "    ratings1: Pandas df, labels\n",
    "    numerical: List of str col. names of numerical columns to keep\n",
    "\n",
    "    out\n",
    "    x: np array\n",
    "    y: np array\n",
    "    merged: Pandas df\n",
    "    \"\"\"\n",
    "    merged = pd.merge(figs_1, ratings1, how='inner', on=[\"Data Date\", \"Ticker Symbol\"])\n",
    "    merged = merged.rename(columns = {'S&P Domestic Long Term Issuer Credit Rating':'rating'})\n",
    "\n",
    "    if len(numerical) == 0:\n",
    "        numerical = ['Current Assets - Total', 'Cash','Long-Term Debt - Total',\n",
    "        'Earnings Per Share (Basic) - Including Extraordinary Items - 12 Months Moving',\n",
    "        'Invested Capital - Total - Quarterly','Inventories - Total', 'Pretax Income',\n",
    "        'Operating Income Before Depreciation']\n",
    "    vals = merged['Data Date'].str[:4]\n",
    "    merged['year'] = vals\n",
    "    # yrs =\n",
    "\n",
    "\n",
    "\n",
    "    merged = merged[(merged['rating'] != 'D') & (merged['rating'] != 'SD')]\n",
    "\n",
    "    counts =  merged['rating'].value_counts()\n",
    "    good_classes = [counts.index[j] for j in range(len(counts)) if counts[j] >=7]\n",
    "    merged = merged[merged['rating'].isin(good_classes)]\n",
    "    if len(years) != 0:\n",
    "        merged = merged[merged['year'].isin(years)]\n",
    "    # merged = merged.drop(['year'], axis=1)\n",
    "    if len(ind_to_keep) == 0:\n",
    "        ind_to_keep = [True]*len(merged)\n",
    "\n",
    "    x = merged.loc[ind_to_keep, numerical].values\n",
    "    y = merged.loc[ind_to_keep,['rating']].values\n",
    "    full = numerical.copy()\n",
    "    full.append('rating')\n",
    "    full.append('year')\n",
    "    full.append('Ticker Symbol')\n",
    "\n",
    "\n",
    "\n",
    "    merged = merged.loc[ind_to_keep, full]\n",
    "\n",
    "\n",
    "    print(\"Intersection of Companies: \", len(merged['Ticker Symbol'].unique()))\n",
    "    return x, y, merged\n",
    "\n",
    "def encode(Y, form='', custom={}):\n",
    "\n",
    "    if custom:\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        if form == 'full':\n",
    "            embed = {'BBB-':-1, 'BBB':0, 'A-':2, 'BBB+':1, 'AA+':7, 'AA':6, 'A':3, 'AA-':5, 'BB':-3, 'BB+':-2,\n",
    "                                'AAA':8, 'B':-6, 'B+':-5, 'A+':4, 'BB-':-4, 'CCC+':-8,'CCC':-9,'CCC-':-10, 'CC+':-11,'CC':-12,\n",
    "                                'CC-':-13,'B-':-7}\n",
    "            labels = ['CCC','CCC+','B-', 'B', 'B+', 'BB-', 'BB', 'BB+', 'BBB-', 'BBB', 'BBB+', 'A-', 'A', 'A+',\n",
    "                   'AA-', 'AA', 'AA+', 'AAA']\n",
    "        elif form == 'stanfurd':\n",
    "            embed = {'BBB-':-1, 'BBB':0, 'A-':2, 'BBB+':1, 'AA+':7, 'AA':6, 'A':3, 'AA-':5, 'BB':-3, 'BB+':-2,\n",
    "                                'AAA':7, 'B':-6, 'B+':-5, 'A+':4, 'BB-':-4, 'CCC+':-8, 'B-':-7}\n",
    "            labels = ['CCC+','B-', 'B', 'B+', 'BB-', 'BB', 'BB+', 'BBB-', 'BBB', 'BBB+', 'A-', 'A', 'A+',\n",
    "                   'AA-', 'AA', 'AA+', 'AAA']\n",
    "        elif form == 'three':\n",
    "            embed = {'BBB-':1, 'BBB':1, 'A-':2, 'BBB+':1, 'AA+':2, 'AA':2, 'A':2, 'AA-':2, 'BB':0, 'BB+':0,\n",
    "                    'AAA':2, 'B':0, 'B+':0, 'A+':2, 'BB-':0, 'CCC+':0, 'B-':0}\n",
    "            labels = ['low', 'med', 'high']\n",
    "        elif form == \"IG\":\n",
    "            embed = {'BBB-':1, 'BBB':1, 'A-':1, 'BBB+':1, 'AA+':1, 'AA':1, 'A':1, 'AA-':1, 'BB':0, 'BB+':0,\n",
    "                    'AAA':1, 'B':0, 'B+':0, 'A+':1, 'BB-':0, 'CCC+':0, 'B-':0}\n",
    "            labels = ['HY', 'IG']\n",
    "\n",
    "        elif form == 'letters':\n",
    "            embed = {'BBB-':3, 'BBB':3, 'A-':4, 'BBB+':3, 'AA+':5, 'AA':5, 'A':4, 'AA-':5, 'BB':2, 'BB+':2,\n",
    "                    'AAA':6, 'B':1, 'B+':1, 'A+':4, 'BB-':2, 'CCC+':0, 'B-':1}\n",
    "            labels = ['CCC', 'B', 'BB', 'BBB', 'A', 'AA','AAA']\n",
    "        # elif form == 'letters ex CCC':\n",
    "        else:\n",
    "            embed = {'BBB-':4, 'BBB':4, 'A-':5, 'BBB+':4, 'AA+':6, 'AA':6, 'A':5, 'AA-':6, 'BB':3, 'BB+':3,\n",
    "                  'AAA':7, 'B':2, 'B+':2, 'A+':5, 'BB-':3, 'CCC+':1, 'B-':2, 'CCC':1,'CCC-':1, 'CC+':0,'CC':0,\n",
    "                    'CC-':0}\n",
    "            labels = ['B', 'BB', 'BBB', 'A', 'AA','AAA']\n",
    "            # colors = ['#630C3A', '#39C8C6', '#D3500C', '#FFB139', '#828282', '#17d8ff', '#1770ff']\n",
    "        Y_emb = np.array([embed[i] for i in Y.T[0]]).ravel()\n",
    "\n",
    "    return Y_emb, labels\n",
    "\n",
    "def decode(Y, form='', custom={}):\n",
    "    if form == 'full':\n",
    "            embed = {-1:'BBB-', 0:'BBB', 2:'A-', 1:'BBB+', 7:'AA+', 6:'AA', 3:'A', 5:'AA-', -3:'BB', -2:'BB+',\n",
    "                            8:'AAA', -6:'B', -5:'B+', 4:'A+', -4:'BB-', -8:'CCC+',-9:'CCC',-10:'CCC-', -11:'CC+',\n",
    "                     -12:'CC', -13:'CC-',-7:'B-'}\n",
    "            labels = ['CC','CC+','CCC', 'CCC+','B-', 'B', 'B+', 'BB-', 'BB', 'BB+', 'BBB-', 'BBB', 'BBB+', 'A-', 'A', 'A+',\n",
    "                   'AA-', 'AA', 'AA+', 'AAA']\n",
    "    Y_emb = np.array([embed[i] for i in Y.T[0]]).ravel()\n",
    "    return Y_emb, labels\n",
    "def data_split(X, Y,full=None, split=[0.7, 0.1], method=\"numer\", smote=False, seed=100, neigh=5):\n",
    "    \"\"\"\n",
    "    split = [ratio of train, ratio of val]\n",
    "    note: ratio of test = 1.0 - (ratio of train + ratio of val)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #### TODO: if smote, give a non-smote Validation set\n",
    "    ## No Validation set\n",
    "    if split[1] == 0.0:\n",
    "        test_split = 1.0 - split[0]\n",
    "\n",
    "        if method == 'numer':\n",
    "            splits = int(np.round(split[0]*X.shape[0]))\n",
    "            cc = list(np.arange(X.shape[0])).copy()\n",
    "            np.random.shuffle(cc)\n",
    "            train_inds = cc[:splits]\n",
    "            test_inds = cc[splits:]\n",
    "            X_train = X[train_inds, :]\n",
    "            Y_train = Y[train_inds]\n",
    "            X_test =  X[test_inds, :]\n",
    "            Y_test =  Y[test_inds]\n",
    "\n",
    "            X_val = []\n",
    "            Y_val = []\n",
    "\n",
    "        # elif method == \"holdout\":\n",
    "            # X is DataFrame\n",
    "            # Y is empty\n",
    "        if smote:\n",
    "            # ks = np.min([np.min(), 5])\n",
    "            dd = {}\n",
    "            uu = {}\n",
    "            kounts = pd.Series(enc_Y).value_counts().to_dict()\n",
    "            max_val = max(kounts.values())\n",
    "            for k,v in kounts.items():\n",
    "              dd[k] = int((max_val - v)*0.2 + v)\n",
    "            for c,d in sorted(kounts.items(), key=lambda item: item[1])[-5:]:\n",
    "              uu[c] = int(d*0.7)\n",
    "\n",
    "            oversample = SMOTE(sampling_strategy=dd, k_neighbors=neigh)\n",
    "            undersample =RandomUnderSampler(sampling_strategy=uu)\n",
    "            steps = [('o', oversample), ('u', undersample)]\n",
    "            pipeline = Pipeline(steps=steps)\n",
    "            # print(\"SVMMMM\")\n",
    "\n",
    "            X_train, Y_train = pipeline.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "    else:\n",
    "        if method == 'numer':\n",
    "            splits = int(np.round(split[0]*X.shape[0]))\n",
    "            splits1 = splits + int(np.round(split[1]*X.shape[0]))\n",
    "            cc = list(np.arange(X.shape[0])).copy()\n",
    "            np.random.shuffle(cc)\n",
    "            train_inds = cc[:splits]\n",
    "            val_inds = cc[splits:splits1]\n",
    "            test_inds = cc[splits1:]\n",
    "\n",
    "            X_train = X[train_inds, :]\n",
    "            Y_train = Y[train_inds]\n",
    "            X_val = X[val_inds, :]\n",
    "            Y_val = Y[val_inds]\n",
    "\n",
    "            X_test =  X[test_inds, :]\n",
    "            Y_test =  Y[test_inds]\n",
    "\n",
    "        if smote:\n",
    "            # ks = np.min([np.min(), 5])\n",
    "            oversample = SMOTE(k_neighbors=neigh)\n",
    "            X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:40:53.456005Z",
     "start_time": "2021-05-10T20:40:53.434749Z"
    },
    "code_folding": [
     0
    ],
    "id": "yQ_amsHrB8Z1"
   },
   "outputs": [],
   "source": [
    "def import_data():\n",
    "  ratings = pd.read_excel(\"../datasets/ratings_all_energ_new.xlsx\")\n",
    "  ratio = pd.read_excel(\"../datasets/ratios_2_all_energ_new.xlsx\")\n",
    "  energ = pd.read_excel(\"../datasets/energ_specific_all_new.xlsx\")\n",
    "  # ratings = pd.read_excel(\"drive/My Drive/Honors Thesis/datasets/ratings_all_energ_new.xlsx\")\n",
    "  # ratio = pd.read_excel(\"drive/My Drive/Honors Thesis/datasets/ratios_2_all_energ_new.xlsx\")\n",
    "  # energ = pd.read_excel(\"drive/My Drive/Honors Thesis/datasets/energ_specific_all_new.xlsx\")\n",
    "  \n",
    "  cols = ratio.columns\n",
    "  ratio = ratio.drop(cols[0], axis=1)\n",
    "  ratio = ratio.rename(columns = {'Public Date':'Data Date','EXCHANGE TICKER SYMBOL - HISTORICAL':'Ticker Symbol'})\n",
    "\n",
    "  ratio1, ratings1 = format_df(ratio.copy(), ratings.copy(), \n",
    "                              ['Trailing P/E to Growth (PEG) ratio','Dividend Yield', \n",
    "                                'Interest/Average Total Debt', 'Free Cash Flow/Operating Cash Flow'])\n",
    "\n",
    "  numer = list(ratio1.columns[4:-1])\n",
    "\n",
    "  cols = energ.columns\n",
    "  # aa = cols[[0,1,2,3,4,5,6, 18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "  aa = cols[[0,1,2,3,4,5,6, 10,11,14,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35]]\n",
    "  energ1 = energ.drop(\n",
    "        aa, \n",
    "      axis=1)\n",
    "  # energ1 = energ_.fillna(energ_.mean()) \n",
    "  # energ1, _ = format_df(energ.copy(), ratings.copy(), \n",
    "  #                             aa)\n",
    "  energ1['Data Date'] = energ1['Data Date'].astype(str)\n",
    "\n",
    "  features = pd.merge(ratio1, energ1,how='left',on=[\"Data Date\", \"Ticker Symbol\"])\n",
    "  # len(features[\"Ticker Symbol\"].unique())\n",
    "  lst3 = [value for value in ratio[\"Ticker Symbol\"].unique() if value in energ[\"Ticker Symbol\"].unique()]\n",
    "  # ratio1[\"Ticker Symbol\"].unique()\n",
    "  # len(lst3)\n",
    "  print(len(ratio[\"Ticker Symbol\"].unique()), len(energ[\"Ticker Symbol\"].unique()), \n",
    "        len(ratio1[\"Ticker Symbol\"].unique()), len(energ1[\"Ticker Symbol\"].unique()))\n",
    "\n",
    "  first_col = features.pop(\"Ticker Symbol\") \n",
    "  ff = len(features.columns)\n",
    "  features.insert(ff, \"Ticker Symbol\", first_col)\n",
    "  numer = list(features.columns[4:-1])\n",
    "\n",
    "  X1,Y1,full1 = join_numerical(features, ratings1, numerical=numer)\n",
    "  return X1,Y1,full1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:40:56.115299Z",
     "start_time": "2021-05-10T20:40:56.106317Z"
    },
    "code_folding": [
     0,
     5
    ],
    "id": "q5oi_RnPKL6m"
   },
   "outputs": [],
   "source": [
    "def plotGD(losses, model):\n",
    "  plt.plot(losses)\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Iterations (in 100s)')\n",
    "  plt.title(model + \" Gradient Descent (ADAM)\")\n",
    "def plotAcc(vals, model):\n",
    "  plt.plot(vals)\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Iterations (in 100s)')\n",
    "  plt.title(model +  \" Gradient Descent (ADAM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:40:56.660362Z",
     "start_time": "2021-05-10T20:40:56.646400Z"
    },
    "code_folding": [],
    "id": "zaAEgc4bD2vw"
   },
   "source": [
    "# process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:41:18.277926Z",
     "start_time": "2021-05-10T20:40:56.782676Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NbgDUmzlEds",
    "outputId": "3c9b0a12-97da-4e2b-b4fa-cdc6d70d723f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Companies in Ratings:  335\n",
      "Unique Companies in Features:  253\n",
      "changed\n",
      "273 819 253 819\n",
      "Intersection of Companies:  97\n"
     ]
    }
   ],
   "source": [
    "X1,Y1,full1 = import_data()\n",
    "\n",
    "X1, X_test_,Y1, Y_test = train_test_split(X1, Y1, test_size=0.2, random_state=100)\n",
    "\n",
    "ss = StandardScaler()\n",
    "scl_X = ss.fit_transform(X1)\n",
    "scl_X = np.nan_to_num(scl_X)\n",
    "enc_Y, _ = encode(Y1, 'full') \n",
    "\n",
    "n_classes = len(np.unique(enc_Y))\n",
    "n_feats = scl_X.shape[1]\n",
    "\n",
    "X_test = ss.transform(X_test_)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "Y_test, _ = encode(Y_test, 'full')\n",
    "minny = np.min((np.min(enc_Y), np.min(Y_test)))\n",
    "\n",
    "enc_Y += np.abs(minny)\n",
    "Y_test += np.abs(minny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:41:24.874353Z",
     "start_time": "2021-05-10T20:41:24.861390Z"
    },
    "id": "PRrtPIM1ztgk"
   },
   "outputs": [],
   "source": [
    "len(np.unique(enc_Y))\n",
    "num_classes = n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:41:26.028341Z",
     "start_time": "2021-05-10T20:41:26.016441Z"
    },
    "id": "Zv18y3DYlEnH"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, _, _,X_val, Y_val = data_split(scl_X, enc_Y, split=[0.8, 0.0], smote=False, seed = 100, neigh=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:41:28.289209Z",
     "start_time": "2021-05-10T20:41:28.266270Z"
    },
    "id": "SpxHT_K9PPQs"
   },
   "outputs": [],
   "source": [
    "Xt_train = torch.FloatTensor(X_train)\n",
    "Yt_train = torch.Tensor(Y_train)\n",
    "Xt_val = torch.FloatTensor(X_val)\n",
    "Yt_val = torch.Tensor(Y_val)\n",
    "\n",
    "Xt_test = torch.FloatTensor(X_test)\n",
    "Yt_test = torch.Tensor(Y_test)\n",
    "\n",
    "train_set = TensorDataset(Xt_train, Yt_train)\n",
    "loader_train = DataLoader(train_set, batch_size=10)\n",
    "\n",
    "val_set = TensorDataset(Xt_val, Yt_val)\n",
    "loader_val = DataLoader(val_set, batch_size=10)\n",
    "\n",
    "test_set = TensorDataset(Xt_test, Yt_test)\n",
    "loader_test = DataLoader(test_set, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:41:59.261401Z",
     "start_time": "2021-05-10T20:41:59.242455Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0wrIsiFqKne",
    "outputId": "cde734e6-c163-46eb-a970-e1c9bd073eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 \n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:42:01.556132Z",
     "start_time": "2021-05-10T20:42:01.537535Z"
    },
    "id": "NAijo0WRb7R3"
   },
   "outputs": [],
   "source": [
    "def validate(loader, model, mode = 0):\n",
    "       \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    last_corr = 0\n",
    "    last_samples = 0\n",
    "    mae = 0.\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    " \n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.float().to(device=device)\n",
    "\n",
    "            if mode == 1:\n",
    "              scores = model(x)\n",
    "              _, preds = scores.max(1)\n",
    "            elif mode == 2:\n",
    "              scores = model(x)\n",
    "              _, preds = scores.max(1)\n",
    "              y = torch.squeeze(y)\n",
    "            elif mode == 3:\n",
    "              scores, probs = model(x)\n",
    "              # _, preds = scores.max(1)\n",
    "              preds = proba_to_label(probs).float()\n",
    "              # y = torch.squeeze(y)\n",
    "              y = torch.flatten(y.view(y.size(0), -1).int())\n",
    "\n",
    "\n",
    "            else:\n",
    "              scores, probs = model(x)\n",
    "            # print(\"scores: \",scores.size())\n",
    "              preds = proba_to_label(probs).float()\n",
    "\n",
    "            # print('preds: ', preds.size(), 'y: ',y.size())\n",
    "            num_correct += (preds == y).sum()\n",
    "            # if y[:, -1] != y[:, -1]: \n",
    "\n",
    "            if mode == 2:\n",
    "              num_samples += preds.size(0) * preds.size(1)\n",
    "              # last_corr += (preds[:, -1] == y[:, -1]).sum()\n",
    "              # last_samples += preds.size(0)            \n",
    "\n",
    "            else:\n",
    "              num_samples += preds.size(0)\n",
    "            mae += torch.sum(torch.abs(preds - y))\n",
    "            # mse += torch.sum((preds - y)**2)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        # if mode ==2:\n",
    "        #   last_acc = float(last_corr) / last_samples\n",
    "        #   print(last_acc)\n",
    "        mae = mae / num_samples\n",
    "        # mse = mse / num_examples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc), f'Mean absolute error: {mae:.2f}')\n",
    "    return acc, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDPsrL8B4uO7"
   },
   "source": [
    "# Train Func.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:42:02.617656Z",
     "start_time": "2021-05-10T20:42:02.601700Z"
    },
    "id": "Ca1e1FVUb7W6"
   },
   "outputs": [],
   "source": [
    "def train_func(model, optimizer, epochs=1, mode=0):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - model: A PyTorch model.\n",
    "    - optimizer: Optimizer object\n",
    "    - epochs: int  \n",
    "    Returns: Lists of validation accuracies at the end of each epoch.\n",
    "    \"\"\"\n",
    "    print(device)\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    val_mae = []\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            # print(y)\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "\n",
    "            if mode == 1:\n",
    "              y = y.to(device=device, dtype=torch.long)\n",
    "              scores = model(x)\n",
    "              \n",
    "              loss = F.cross_entropy(scores, y)\n",
    "            # LSTM  \n",
    "            elif mode == 2:\n",
    "              ## LSTM Mode\n",
    "              y = y.to(device=device, dtype=torch.long)\n",
    "              y = torch.squeeze(y)\n",
    "              scores = model(x)\n",
    "\n",
    "              # print(scores.size(), y.size())\n",
    "              loss = F.cross_entropy(scores, y)\n",
    "            # OR-LSTM\n",
    "            elif mode == 3:\n",
    "              # print(torch.flatten(y.view(y.size(0), -1).int()).size())\n",
    "              # print(\"nums :\", num_classes)\n",
    "              levels = levels_from_labelbatch(torch.flatten(y.view(y.size(0), -1).int()), num_classes=num_classes + 1)\n",
    "              # print('lev: ', levels.size())\n",
    "              levels = levels.to(device=device, dtype=torch.long)\n",
    "              # print(\"levels: \",levels.size())\n",
    "              scores, probs = model(x)\n",
    "              # print('s:',scores.size(), 'lev: ', levels.size())\n",
    "              loss = coral_loss(scores, levels)\n",
    "\n",
    "            # CORAL\n",
    "            else:\n",
    "              levels = levels_from_labelbatch(y.int(), num_classes=num_classes)\n",
    "              levels = levels.to(device=device, dtype=torch.long)\n",
    "              scores, probs = model(x)\n",
    "              loss = coral_loss(scores, levels)    \n",
    "\n",
    "            # print(scores)\n",
    "            # print(scores.size(), y.size())\n",
    "            # loss = F.nll_loss(scores, y, reduction='sum')\n",
    "            # loss = OrdinalEntropyLoss(scores, y)\n",
    "\n",
    "            # print(loss.size())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                losses.append(loss.item())\n",
    "                validate(loader_val, model, mode)\n",
    "                print()\n",
    "        acc_, mae_ = validate(loader_val, model, mode)\n",
    "        val_accs.append(acc_)\n",
    "        val_mae.append(mae_)\n",
    "        \n",
    "    return val_accs, val_mae, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORAL NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:42:03.290792Z",
     "start_time": "2021-05-10T20:42:03.277369Z"
    },
    "id": "900P3wAuwh0_"
   },
   "outputs": [],
   "source": [
    "class CoralNet(nn.Module):\n",
    "  def __init__(self, num_classes, num_features,                              \n",
    "                                    hidden_layer_size = 100 ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.features = torch.nn.Sequential(\n",
    "        nn.Linear(num_features, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        )\n",
    "\n",
    "    self.fc = CoralLayer(hidden_layer_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    logits =  self.fc(x)\n",
    "    probas = torch.sigmoid(logits)\n",
    "\n",
    "    return logits, probas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7mBXgjSAIir"
   },
   "source": [
    "# Baseline Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:42:04.414482Z",
     "start_time": "2021-05-10T20:42:04.402512Z"
    },
    "id": "4_d3f3nL2-VF"
   },
   "outputs": [],
   "source": [
    "class NormalNet(nn.Module):\n",
    "  def __init__(self, num_classes, num_features,                              \n",
    "                                    hidden_layer_size = 100 ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.features = torch.nn.Sequential(\n",
    "        nn.Linear(num_features, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "    self.fc = nn.Linear(hidden_layer_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    logits =  self.fc(x)\n",
    "\n",
    "\n",
    "    return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:42:04.975530Z",
     "start_time": "2021-05-10T20:42:04.957612Z"
    },
    "id": "lzH38xY2eVlZ"
   },
   "outputs": [],
   "source": [
    "num_features = n_feats\n",
    "learning_rate = 7e-4\n",
    "hidden_layer_size = 250 \n",
    "epics = 100\n",
    "\n",
    "num_classes = n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqFvODLNAqM8"
   },
   "source": [
    "# CORAL NN: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:49:57.406564Z",
     "start_time": "2021-05-10T20:42:06.081970Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKu9IBarb7bz",
    "outputId": "eafd788a-1c6f-484f-c038-54fa45ce9595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Iteration 0, loss = 11.8045\n",
      "Got 19 / 1275 correct (1.49) Mean absolute error: 6.35\n",
      "\n",
      "Iteration 100, loss = 10.6102\n",
      "Got 33 / 1275 correct (2.59) Mean absolute error: 6.00\n",
      "\n",
      "Iteration 200, loss = 9.0341\n",
      "Got 40 / 1275 correct (3.14) Mean absolute error: 5.32\n",
      "\n",
      "Iteration 300, loss = 9.5567\n",
      "Got 75 / 1275 correct (5.88) Mean absolute error: 4.69\n",
      "\n",
      "Iteration 400, loss = 9.5802\n",
      "Got 78 / 1275 correct (6.12) Mean absolute error: 4.34\n",
      "\n",
      "Iteration 500, loss = 8.7052\n",
      "Got 101 / 1275 correct (7.92) Mean absolute error: 3.78\n",
      "\n",
      "Got 66 / 1275 correct (5.18) Mean absolute error: 4.55\n",
      "Iteration 0, loss = 8.9930\n",
      "Got 64 / 1275 correct (5.02) Mean absolute error: 4.56\n",
      "\n",
      "Iteration 100, loss = 8.9328\n",
      "Got 139 / 1275 correct (10.90) Mean absolute error: 3.16\n",
      "\n",
      "Iteration 200, loss = 7.0834\n",
      "Got 135 / 1275 correct (10.59) Mean absolute error: 3.15\n",
      "\n",
      "Iteration 300, loss = 8.0294\n",
      "Got 157 / 1275 correct (12.31) Mean absolute error: 3.21\n",
      "\n",
      "Iteration 400, loss = 7.8141\n",
      "Got 226 / 1275 correct (17.73) Mean absolute error: 2.51\n",
      "\n",
      "Iteration 500, loss = 7.4468\n",
      "Got 135 / 1275 correct (10.59) Mean absolute error: 2.92\n",
      "\n",
      "Got 123 / 1275 correct (9.65) Mean absolute error: 2.91\n",
      "Iteration 0, loss = 7.3161\n",
      "Got 130 / 1275 correct (10.20) Mean absolute error: 2.86\n",
      "\n",
      "Iteration 100, loss = 7.5612\n",
      "Got 189 / 1275 correct (14.82) Mean absolute error: 2.40\n",
      "\n",
      "Iteration 200, loss = 5.9122\n",
      "Got 224 / 1275 correct (17.57) Mean absolute error: 2.16\n",
      "\n",
      "Iteration 300, loss = 7.0146\n",
      "Got 274 / 1275 correct (21.49) Mean absolute error: 1.84\n",
      "\n",
      "Iteration 400, loss = 6.8040\n",
      "Got 283 / 1275 correct (22.20) Mean absolute error: 1.83\n",
      "\n",
      "Iteration 500, loss = 6.5213\n",
      "Got 183 / 1275 correct (14.35) Mean absolute error: 2.21\n",
      "\n",
      "Got 218 / 1275 correct (17.10) Mean absolute error: 2.07\n",
      "Iteration 0, loss = 6.4159\n",
      "Got 216 / 1275 correct (16.94) Mean absolute error: 2.06\n",
      "\n",
      "Iteration 100, loss = 6.4886\n",
      "Got 265 / 1275 correct (20.78) Mean absolute error: 1.90\n",
      "\n",
      "Iteration 200, loss = 5.1365\n",
      "Got 255 / 1275 correct (20.00) Mean absolute error: 1.75\n",
      "\n",
      "Iteration 300, loss = 6.1594\n",
      "Got 320 / 1275 correct (25.10) Mean absolute error: 1.50\n",
      "\n",
      "Iteration 400, loss = 5.8185\n",
      "Got 303 / 1275 correct (23.76) Mean absolute error: 1.64\n",
      "\n",
      "Iteration 500, loss = 5.9247\n",
      "Got 308 / 1275 correct (24.16) Mean absolute error: 1.67\n",
      "\n",
      "Got 227 / 1275 correct (17.80) Mean absolute error: 1.77\n",
      "Iteration 0, loss = 5.7080\n",
      "Got 229 / 1275 correct (17.96) Mean absolute error: 1.76\n",
      "\n",
      "Iteration 100, loss = 5.6683\n",
      "Got 350 / 1275 correct (27.45) Mean absolute error: 1.52\n",
      "\n",
      "Iteration 200, loss = 4.5388\n",
      "Got 278 / 1275 correct (21.80) Mean absolute error: 1.52\n",
      "\n",
      "Iteration 300, loss = 5.5247\n",
      "Got 371 / 1275 correct (29.10) Mean absolute error: 1.25\n",
      "\n",
      "Iteration 400, loss = 5.2139\n",
      "Got 325 / 1275 correct (25.49) Mean absolute error: 1.40\n",
      "\n",
      "Iteration 500, loss = 5.1372\n",
      "Got 320 / 1275 correct (25.10) Mean absolute error: 1.52\n",
      "\n",
      "Got 288 / 1275 correct (22.59) Mean absolute error: 1.56\n",
      "Iteration 0, loss = 5.1083\n",
      "Got 283 / 1275 correct (22.20) Mean absolute error: 1.55\n",
      "\n",
      "Iteration 100, loss = 5.0583\n",
      "Got 382 / 1275 correct (29.96) Mean absolute error: 1.30\n",
      "\n",
      "Iteration 200, loss = 4.0554\n",
      "Got 347 / 1275 correct (27.22) Mean absolute error: 1.32\n",
      "\n",
      "Iteration 300, loss = 4.9256\n",
      "Got 387 / 1275 correct (30.35) Mean absolute error: 1.14\n",
      "\n",
      "Iteration 400, loss = 4.8854\n",
      "Got 374 / 1275 correct (29.33) Mean absolute error: 1.30\n",
      "\n",
      "Iteration 500, loss = 4.6679\n",
      "Got 358 / 1275 correct (28.08) Mean absolute error: 1.35\n",
      "\n",
      "Got 346 / 1275 correct (27.14) Mean absolute error: 1.33\n",
      "Iteration 0, loss = 7.1399\n",
      "Got 349 / 1275 correct (27.37) Mean absolute error: 1.32\n",
      "\n",
      "Iteration 100, loss = 4.5605\n",
      "Got 399 / 1275 correct (31.29) Mean absolute error: 1.14\n",
      "\n",
      "Iteration 200, loss = 3.6814\n",
      "Got 361 / 1275 correct (28.31) Mean absolute error: 1.24\n",
      "\n",
      "Iteration 300, loss = 4.4615\n",
      "Got 424 / 1275 correct (33.25) Mean absolute error: 1.08\n",
      "\n",
      "Iteration 400, loss = 4.3024\n",
      "Got 402 / 1275 correct (31.53) Mean absolute error: 1.17\n",
      "\n",
      "Iteration 500, loss = 4.3307\n",
      "Got 395 / 1275 correct (30.98) Mean absolute error: 1.18\n",
      "\n",
      "Got 365 / 1275 correct (28.63) Mean absolute error: 1.26\n",
      "Iteration 0, loss = 4.9535\n",
      "Got 375 / 1275 correct (29.41) Mean absolute error: 1.26\n",
      "\n",
      "Iteration 100, loss = 4.1274\n",
      "Got 427 / 1275 correct (33.49) Mean absolute error: 1.12\n",
      "\n",
      "Iteration 200, loss = 3.3843\n",
      "Got 400 / 1275 correct (31.37) Mean absolute error: 1.15\n",
      "\n",
      "Iteration 300, loss = 4.1038\n",
      "Got 428 / 1275 correct (33.57) Mean absolute error: 1.04\n",
      "\n",
      "Iteration 400, loss = 3.8570\n",
      "Got 458 / 1275 correct (35.92) Mean absolute error: 1.04\n",
      "\n",
      "Iteration 500, loss = 3.8832\n",
      "Got 430 / 1275 correct (33.73) Mean absolute error: 1.07\n",
      "\n",
      "Got 385 / 1275 correct (30.20) Mean absolute error: 1.21\n",
      "Iteration 0, loss = 4.1810\n",
      "Got 392 / 1275 correct (30.75) Mean absolute error: 1.19\n",
      "\n",
      "Iteration 100, loss = 3.8088\n",
      "Got 477 / 1275 correct (37.41) Mean absolute error: 0.97\n",
      "\n",
      "Iteration 200, loss = 3.1332\n",
      "Got 455 / 1275 correct (35.69) Mean absolute error: 1.09\n",
      "\n",
      "Iteration 300, loss = 3.8200\n",
      "Got 412 / 1275 correct (32.31) Mean absolute error: 1.10\n",
      "\n",
      "Iteration 400, loss = 3.5427\n",
      "Got 464 / 1275 correct (36.39) Mean absolute error: 1.01\n",
      "\n",
      "Iteration 500, loss = 3.5664\n",
      "Got 491 / 1275 correct (38.51) Mean absolute error: 0.92\n",
      "\n",
      "Got 437 / 1275 correct (34.27) Mean absolute error: 1.03\n",
      "Iteration 0, loss = 3.8339\n",
      "Got 426 / 1275 correct (33.41) Mean absolute error: 1.05\n",
      "\n",
      "Iteration 100, loss = 3.5000\n",
      "Got 474 / 1275 correct (37.18) Mean absolute error: 0.97\n",
      "\n",
      "Iteration 200, loss = 2.8947\n",
      "Got 434 / 1275 correct (34.04) Mean absolute error: 1.13\n",
      "\n",
      "Iteration 300, loss = 3.5422\n",
      "Got 480 / 1275 correct (37.65) Mean absolute error: 0.99\n",
      "\n",
      "Iteration 400, loss = 3.2597\n",
      "Got 479 / 1275 correct (37.57) Mean absolute error: 0.95\n",
      "\n",
      "Iteration 500, loss = 3.3063\n",
      "Got 466 / 1275 correct (36.55) Mean absolute error: 0.93\n",
      "\n",
      "Got 442 / 1275 correct (34.67) Mean absolute error: 0.97\n",
      "Iteration 0, loss = 3.6204\n",
      "Got 445 / 1275 correct (34.90) Mean absolute error: 0.98\n",
      "\n",
      "Iteration 100, loss = 3.3011\n",
      "Got 472 / 1275 correct (37.02) Mean absolute error: 1.00\n",
      "\n",
      "Iteration 200, loss = 2.7165\n",
      "Got 486 / 1275 correct (38.12) Mean absolute error: 0.98\n",
      "\n",
      "Iteration 300, loss = 3.2757\n",
      "Got 482 / 1275 correct (37.80) Mean absolute error: 0.94\n",
      "\n",
      "Iteration 400, loss = 3.0288\n",
      "Got 503 / 1275 correct (39.45) Mean absolute error: 0.88\n",
      "\n",
      "Iteration 500, loss = 3.0885\n",
      "Got 510 / 1275 correct (40.00) Mean absolute error: 0.87\n",
      "\n",
      "Got 505 / 1275 correct (39.61) Mean absolute error: 0.85\n",
      "Iteration 0, loss = 3.7476\n",
      "Got 514 / 1275 correct (40.31) Mean absolute error: 0.84\n",
      "\n",
      "Iteration 100, loss = 3.0284\n",
      "Got 486 / 1275 correct (38.12) Mean absolute error: 0.87\n",
      "\n",
      "Iteration 200, loss = 2.5832\n",
      "Got 489 / 1275 correct (38.35) Mean absolute error: 0.96\n",
      "\n",
      "Iteration 300, loss = 3.0701\n",
      "Got 511 / 1275 correct (40.08) Mean absolute error: 0.86\n",
      "\n",
      "Iteration 400, loss = 2.8248\n",
      "Got 510 / 1275 correct (40.00) Mean absolute error: 0.86\n",
      "\n",
      "Iteration 500, loss = 2.8865\n",
      "Got 543 / 1275 correct (42.59) Mean absolute error: 0.80\n",
      "\n",
      "Got 496 / 1275 correct (38.90) Mean absolute error: 0.90\n",
      "Iteration 0, loss = 3.2250\n",
      "Got 487 / 1275 correct (38.20) Mean absolute error: 0.91\n",
      "\n",
      "Iteration 100, loss = 2.9570\n",
      "Got 513 / 1275 correct (40.24) Mean absolute error: 0.88\n",
      "\n",
      "Iteration 200, loss = 2.4447\n",
      "Got 535 / 1275 correct (41.96) Mean absolute error: 0.84\n",
      "\n",
      "Iteration 300, loss = 2.8746\n",
      "Got 544 / 1275 correct (42.67) Mean absolute error: 0.85\n",
      "\n",
      "Iteration 400, loss = 2.6962\n",
      "Got 556 / 1275 correct (43.61) Mean absolute error: 0.78\n",
      "\n",
      "Iteration 500, loss = 2.8013\n",
      "Got 575 / 1275 correct (45.10) Mean absolute error: 0.77\n",
      "\n",
      "Got 572 / 1275 correct (44.86) Mean absolute error: 0.75\n",
      "Iteration 0, loss = 3.0752\n",
      "Got 576 / 1275 correct (45.18) Mean absolute error: 0.75\n",
      "\n",
      "Iteration 100, loss = 2.6785\n",
      "Got 509 / 1275 correct (39.92) Mean absolute error: 0.84\n",
      "\n",
      "Iteration 200, loss = 2.2698\n",
      "Got 527 / 1275 correct (41.33) Mean absolute error: 0.84\n",
      "\n",
      "Iteration 300, loss = 2.7176\n",
      "Got 591 / 1275 correct (46.35) Mean absolute error: 0.78\n",
      "\n",
      "Iteration 400, loss = 2.4982\n",
      "Got 575 / 1275 correct (45.10) Mean absolute error: 0.77\n",
      "\n",
      "Iteration 500, loss = 2.6589\n",
      "Got 619 / 1275 correct (48.55) Mean absolute error: 0.68\n",
      "\n",
      "Got 589 / 1275 correct (46.20) Mean absolute error: 0.72\n",
      "Iteration 0, loss = 2.9475\n",
      "Got 603 / 1275 correct (47.29) Mean absolute error: 0.71\n",
      "\n",
      "Iteration 100, loss = 2.6990\n",
      "Got 612 / 1275 correct (48.00) Mean absolute error: 0.72\n",
      "\n",
      "Iteration 200, loss = 2.1707\n",
      "Got 569 / 1275 correct (44.63) Mean absolute error: 0.76\n",
      "\n",
      "Iteration 300, loss = 2.5718\n",
      "Got 603 / 1275 correct (47.29) Mean absolute error: 0.71\n",
      "\n",
      "Iteration 400, loss = 2.3623\n",
      "Got 630 / 1275 correct (49.41) Mean absolute error: 0.66\n",
      "\n",
      "Iteration 500, loss = 2.4931\n",
      "Got 634 / 1275 correct (49.73) Mean absolute error: 0.64\n",
      "\n",
      "Got 603 / 1275 correct (47.29) Mean absolute error: 0.70\n",
      "Iteration 0, loss = 3.0490\n",
      "Got 604 / 1275 correct (47.37) Mean absolute error: 0.70\n",
      "\n",
      "Iteration 100, loss = 2.4199\n",
      "Got 630 / 1275 correct (49.41) Mean absolute error: 0.67\n",
      "\n",
      "Iteration 200, loss = 2.0347\n",
      "Got 620 / 1275 correct (48.63) Mean absolute error: 0.66\n",
      "\n",
      "Iteration 300, loss = 2.4329\n",
      "Got 629 / 1275 correct (49.33) Mean absolute error: 0.70\n",
      "\n",
      "Iteration 400, loss = 2.2406\n",
      "Got 639 / 1275 correct (50.12) Mean absolute error: 0.68\n",
      "\n",
      "Iteration 500, loss = 2.3522\n",
      "Got 590 / 1275 correct (46.27) Mean absolute error: 0.72\n",
      "\n",
      "Got 625 / 1275 correct (49.02) Mean absolute error: 0.70\n",
      "Iteration 0, loss = 2.8004\n",
      "Got 620 / 1275 correct (48.63) Mean absolute error: 0.71\n",
      "\n",
      "Iteration 100, loss = 2.4143\n",
      "Got 634 / 1275 correct (49.73) Mean absolute error: 0.68\n",
      "\n",
      "Iteration 200, loss = 1.9385\n",
      "Got 604 / 1275 correct (47.37) Mean absolute error: 0.72\n",
      "\n",
      "Iteration 300, loss = 2.2984\n",
      "Got 695 / 1275 correct (54.51) Mean absolute error: 0.64\n",
      "\n",
      "Iteration 400, loss = 2.1537\n",
      "Got 669 / 1275 correct (52.47) Mean absolute error: 0.64\n",
      "\n",
      "Iteration 500, loss = 2.2332\n",
      "Got 667 / 1275 correct (52.31) Mean absolute error: 0.64\n",
      "\n",
      "Got 645 / 1275 correct (50.59) Mean absolute error: 0.64\n",
      "Iteration 0, loss = 2.8181\n",
      "Got 639 / 1275 correct (50.12) Mean absolute error: 0.65\n",
      "\n",
      "Iteration 100, loss = 2.3270\n",
      "Got 620 / 1275 correct (48.63) Mean absolute error: 0.71\n",
      "\n",
      "Iteration 200, loss = 1.8499\n",
      "Got 571 / 1275 correct (44.78) Mean absolute error: 0.80\n",
      "\n",
      "Iteration 300, loss = 2.1849\n",
      "Got 655 / 1275 correct (51.37) Mean absolute error: 0.70\n",
      "\n",
      "Iteration 400, loss = 2.0116\n",
      "Got 628 / 1275 correct (49.25) Mean absolute error: 0.68\n",
      "\n",
      "Iteration 500, loss = 2.1720\n",
      "Got 623 / 1275 correct (48.86) Mean absolute error: 0.67\n",
      "\n",
      "Got 659 / 1275 correct (51.69) Mean absolute error: 0.65\n",
      "Iteration 0, loss = 2.7076\n",
      "Got 657 / 1275 correct (51.53) Mean absolute error: 0.64\n",
      "\n",
      "Iteration 100, loss = 2.1628\n",
      "Got 705 / 1275 correct (55.29) Mean absolute error: 0.60\n",
      "\n",
      "Iteration 200, loss = 1.8310\n",
      "Got 579 / 1275 correct (45.41) Mean absolute error: 0.81\n",
      "\n",
      "Iteration 300, loss = 2.0639\n",
      "Got 671 / 1275 correct (52.63) Mean absolute error: 0.66\n",
      "\n",
      "Iteration 400, loss = 1.9266\n",
      "Got 688 / 1275 correct (53.96) Mean absolute error: 0.62\n",
      "\n",
      "Iteration 500, loss = 2.1823\n",
      "Got 660 / 1275 correct (51.76) Mean absolute error: 0.65\n",
      "\n",
      "Got 666 / 1275 correct (52.24) Mean absolute error: 0.65\n",
      "Iteration 0, loss = 2.7068\n",
      "Got 661 / 1275 correct (51.84) Mean absolute error: 0.66\n",
      "\n",
      "Iteration 100, loss = 2.3116\n",
      "Got 645 / 1275 correct (50.59) Mean absolute error: 0.69\n",
      "\n",
      "Iteration 200, loss = 1.7486\n",
      "Got 642 / 1275 correct (50.35) Mean absolute error: 0.65\n",
      "\n",
      "Iteration 300, loss = 2.0490\n",
      "Got 681 / 1275 correct (53.41) Mean absolute error: 0.69\n",
      "\n",
      "Iteration 400, loss = 1.9473\n",
      "Got 681 / 1275 correct (53.41) Mean absolute error: 0.66\n",
      "\n",
      "Iteration 500, loss = 2.0167\n",
      "Got 664 / 1275 correct (52.08) Mean absolute error: 0.62\n",
      "\n",
      "Got 684 / 1275 correct (53.65) Mean absolute error: 0.63\n",
      "Iteration 0, loss = 2.8187\n",
      "Got 691 / 1275 correct (54.20) Mean absolute error: 0.62\n",
      "\n",
      "Iteration 100, loss = 2.0659\n",
      "Got 730 / 1275 correct (57.25) Mean absolute error: 0.57\n",
      "\n",
      "Iteration 200, loss = 1.6410\n",
      "Got 760 / 1275 correct (59.61) Mean absolute error: 0.54\n",
      "\n",
      "Iteration 300, loss = 1.9157\n",
      "Got 742 / 1275 correct (58.20) Mean absolute error: 0.60\n",
      "\n",
      "Iteration 400, loss = 1.7896\n",
      "Got 776 / 1275 correct (60.86) Mean absolute error: 0.53\n",
      "\n",
      "Iteration 500, loss = 1.9549\n",
      "Got 760 / 1275 correct (59.61) Mean absolute error: 0.52\n",
      "\n",
      "Got 727 / 1275 correct (57.02) Mean absolute error: 0.54\n",
      "Iteration 0, loss = 2.4176\n",
      "Got 714 / 1275 correct (56.00) Mean absolute error: 0.55\n",
      "\n",
      "Iteration 100, loss = 2.0213\n",
      "Got 762 / 1275 correct (59.76) Mean absolute error: 0.51\n",
      "\n",
      "Iteration 200, loss = 1.5845\n",
      "Got 769 / 1275 correct (60.31) Mean absolute error: 0.50\n",
      "\n",
      "Iteration 300, loss = 1.7909\n",
      "Got 759 / 1275 correct (59.53) Mean absolute error: 0.54\n",
      "\n",
      "Iteration 400, loss = 1.6783\n",
      "Got 779 / 1275 correct (61.10) Mean absolute error: 0.51\n",
      "\n",
      "Iteration 500, loss = 2.0057\n",
      "Got 745 / 1275 correct (58.43) Mean absolute error: 0.53\n",
      "\n",
      "Got 783 / 1275 correct (61.41) Mean absolute error: 0.48\n",
      "Iteration 0, loss = 2.3546\n",
      "Got 786 / 1275 correct (61.65) Mean absolute error: 0.48\n",
      "\n",
      "Iteration 100, loss = 1.9914\n",
      "Got 784 / 1275 correct (61.49) Mean absolute error: 0.48\n",
      "\n",
      "Iteration 200, loss = 1.4728\n",
      "Got 799 / 1275 correct (62.67) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 300, loss = 1.7474\n",
      "Got 779 / 1275 correct (61.10) Mean absolute error: 0.53\n",
      "\n",
      "Iteration 400, loss = 1.6292\n",
      "Got 748 / 1275 correct (58.67) Mean absolute error: 0.56\n",
      "\n",
      "Iteration 500, loss = 2.2020\n",
      "Got 622 / 1275 correct (48.78) Mean absolute error: 0.69\n",
      "\n",
      "Got 660 / 1275 correct (51.76) Mean absolute error: 0.70\n",
      "Iteration 0, loss = 2.4000\n",
      "Got 666 / 1275 correct (52.24) Mean absolute error: 0.70\n",
      "\n",
      "Iteration 100, loss = 1.7394\n",
      "Got 770 / 1275 correct (60.39) Mean absolute error: 0.52\n",
      "\n",
      "Iteration 200, loss = 1.4218\n",
      "Got 711 / 1275 correct (55.76) Mean absolute error: 0.62\n",
      "\n",
      "Iteration 300, loss = 1.6645\n",
      "Got 783 / 1275 correct (61.41) Mean absolute error: 0.51\n",
      "\n",
      "Iteration 400, loss = 1.5954\n",
      "Got 799 / 1275 correct (62.67) Mean absolute error: 0.49\n",
      "\n",
      "Iteration 500, loss = 1.7843\n",
      "Got 794 / 1275 correct (62.27) Mean absolute error: 0.48\n",
      "\n",
      "Got 803 / 1275 correct (62.98) Mean absolute error: 0.47\n",
      "Iteration 0, loss = 2.1313\n",
      "Got 797 / 1275 correct (62.51) Mean absolute error: 0.48\n",
      "\n",
      "Iteration 100, loss = 1.7786\n",
      "Got 803 / 1275 correct (62.98) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 200, loss = 1.3815\n",
      "Got 807 / 1275 correct (63.29) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 300, loss = 1.6362\n",
      "Got 763 / 1275 correct (59.84) Mean absolute error: 0.51\n",
      "\n",
      "Iteration 400, loss = 1.5190\n",
      "Got 807 / 1275 correct (63.29) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 500, loss = 1.7680\n",
      "Got 780 / 1275 correct (61.18) Mean absolute error: 0.49\n",
      "\n",
      "Got 743 / 1275 correct (58.27) Mean absolute error: 0.52\n",
      "Iteration 0, loss = 1.9103\n",
      "Got 750 / 1275 correct (58.82) Mean absolute error: 0.52\n",
      "\n",
      "Iteration 100, loss = 1.6641\n",
      "Got 798 / 1275 correct (62.59) Mean absolute error: 0.49\n",
      "\n",
      "Iteration 200, loss = 1.3349\n",
      "Got 722 / 1275 correct (56.63) Mean absolute error: 0.59\n",
      "\n",
      "Iteration 300, loss = 1.6620\n",
      "Got 779 / 1275 correct (61.10) Mean absolute error: 0.55\n",
      "\n",
      "Iteration 400, loss = 1.4681\n",
      "Got 812 / 1275 correct (63.69) Mean absolute error: 0.50\n",
      "\n",
      "Iteration 500, loss = 1.6479\n",
      "Got 838 / 1275 correct (65.73) Mean absolute error: 0.45\n",
      "\n",
      "Got 805 / 1275 correct (63.14) Mean absolute error: 0.48\n",
      "Iteration 0, loss = 2.0706\n",
      "Got 807 / 1275 correct (63.29) Mean absolute error: 0.48\n",
      "\n",
      "Iteration 100, loss = 1.6360\n",
      "Got 829 / 1275 correct (65.02) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 200, loss = 1.2619\n",
      "Got 814 / 1275 correct (63.84) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 300, loss = 1.4929\n",
      "Got 816 / 1275 correct (64.00) Mean absolute error: 0.50\n",
      "\n",
      "Iteration 400, loss = 1.4375\n",
      "Got 828 / 1275 correct (64.94) Mean absolute error: 0.45\n",
      "\n",
      "Iteration 500, loss = 1.7093\n",
      "Got 799 / 1275 correct (62.67) Mean absolute error: 0.49\n",
      "\n",
      "Got 779 / 1275 correct (61.10) Mean absolute error: 0.52\n",
      "Iteration 0, loss = 2.5766\n",
      "Got 786 / 1275 correct (61.65) Mean absolute error: 0.52\n",
      "\n",
      "Iteration 100, loss = 1.5637\n",
      "Got 859 / 1275 correct (67.37) Mean absolute error: 0.42\n",
      "\n",
      "Iteration 200, loss = 1.2509\n",
      "Got 833 / 1275 correct (65.33) Mean absolute error: 0.46\n",
      "\n",
      "Iteration 300, loss = 1.4857\n",
      "Got 831 / 1275 correct (65.18) Mean absolute error: 0.50\n",
      "\n",
      "Iteration 400, loss = 1.3799\n",
      "Got 803 / 1275 correct (62.98) Mean absolute error: 0.49\n",
      "\n",
      "Iteration 500, loss = 1.6899\n",
      "Got 828 / 1275 correct (64.94) Mean absolute error: 0.45\n",
      "\n",
      "Got 809 / 1275 correct (63.45) Mean absolute error: 0.48\n",
      "Iteration 0, loss = 2.2671\n",
      "Got 805 / 1275 correct (63.14) Mean absolute error: 0.48\n",
      "\n",
      "Iteration 100, loss = 1.5031\n",
      "Got 838 / 1275 correct (65.73) Mean absolute error: 0.43\n",
      "\n",
      "Iteration 200, loss = 1.1918\n",
      "Got 854 / 1275 correct (66.98) Mean absolute error: 0.41\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 300, loss = 1.4555\n",
      "Got 770 / 1275 correct (60.39) Mean absolute error: 0.55\n",
      "\n",
      "Iteration 400, loss = 1.3701\n",
      "Got 762 / 1275 correct (59.76) Mean absolute error: 0.54\n",
      "\n",
      "Iteration 500, loss = 1.6177\n",
      "Got 823 / 1275 correct (64.55) Mean absolute error: 0.45\n",
      "\n",
      "Got 811 / 1275 correct (63.61) Mean absolute error: 0.48\n",
      "Iteration 0, loss = 1.9364\n",
      "Got 806 / 1275 correct (63.22) Mean absolute error: 0.48\n",
      "\n",
      "Iteration 100, loss = 1.5658\n",
      "Got 813 / 1275 correct (63.76) Mean absolute error: 0.50\n",
      "\n",
      "Iteration 200, loss = 1.1873\n",
      "Got 758 / 1275 correct (59.45) Mean absolute error: 0.55\n",
      "\n",
      "Iteration 300, loss = 1.3885\n",
      "Got 810 / 1275 correct (63.53) Mean absolute error: 0.51\n",
      "\n",
      "Iteration 400, loss = 1.3103\n",
      "Got 839 / 1275 correct (65.80) Mean absolute error: 0.45\n",
      "\n",
      "Iteration 500, loss = 1.5887\n",
      "Got 794 / 1275 correct (62.27) Mean absolute error: 0.51\n",
      "\n",
      "Got 808 / 1275 correct (63.37) Mean absolute error: 0.50\n",
      "Iteration 0, loss = 1.6807\n",
      "Got 812 / 1275 correct (63.69) Mean absolute error: 0.49\n",
      "\n",
      "Iteration 100, loss = 1.5423\n",
      "Got 795 / 1275 correct (62.35) Mean absolute error: 0.48\n",
      "\n",
      "Iteration 200, loss = 1.1389\n",
      "Got 824 / 1275 correct (64.63) Mean absolute error: 0.46\n",
      "\n",
      "Iteration 300, loss = 1.3041\n",
      "Got 824 / 1275 correct (64.63) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 400, loss = 1.2934\n",
      "Got 882 / 1275 correct (69.18) Mean absolute error: 0.40\n",
      "\n",
      "Iteration 500, loss = 1.5466\n",
      "Got 873 / 1275 correct (68.47) Mean absolute error: 0.40\n",
      "\n",
      "Got 888 / 1275 correct (69.65) Mean absolute error: 0.39\n",
      "Iteration 0, loss = 1.9360\n",
      "Got 889 / 1275 correct (69.73) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 100, loss = 1.4562\n",
      "Got 873 / 1275 correct (68.47) Mean absolute error: 0.38\n",
      "\n",
      "Iteration 200, loss = 1.1103\n",
      "Got 878 / 1275 correct (68.86) Mean absolute error: 0.40\n",
      "\n",
      "Iteration 300, loss = 1.2900\n",
      "Got 850 / 1275 correct (66.67) Mean absolute error: 0.44\n",
      "\n",
      "Iteration 400, loss = 1.2410\n",
      "Got 872 / 1275 correct (68.39) Mean absolute error: 0.42\n",
      "\n",
      "Iteration 500, loss = 1.4249\n",
      "Got 888 / 1275 correct (69.65) Mean absolute error: 0.38\n",
      "\n",
      "Got 899 / 1275 correct (70.51) Mean absolute error: 0.37\n",
      "Iteration 0, loss = 1.4616\n",
      "Got 899 / 1275 correct (70.51) Mean absolute error: 0.37\n",
      "\n",
      "Iteration 100, loss = 1.4661\n",
      "Got 877 / 1275 correct (68.78) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 200, loss = 1.0376\n",
      "Got 879 / 1275 correct (68.94) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 300, loss = 1.2357\n",
      "Got 868 / 1275 correct (68.08) Mean absolute error: 0.40\n",
      "\n",
      "Iteration 400, loss = 1.2224\n",
      "Got 887 / 1275 correct (69.57) Mean absolute error: 0.38\n",
      "\n",
      "Iteration 500, loss = 1.6467\n",
      "Got 921 / 1275 correct (72.24) Mean absolute error: 0.35\n",
      "\n",
      "Got 910 / 1275 correct (71.37) Mean absolute error: 0.37\n",
      "Iteration 0, loss = 2.3706\n",
      "Got 915 / 1275 correct (71.76) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 100, loss = 1.3343\n",
      "Got 915 / 1275 correct (71.76) Mean absolute error: 0.34\n",
      "\n",
      "Iteration 200, loss = 1.0678\n",
      "Got 734 / 1275 correct (57.57) Mean absolute error: 0.60\n",
      "\n",
      "Iteration 300, loss = 1.2330\n",
      "Got 812 / 1275 correct (63.69) Mean absolute error: 0.52\n",
      "\n",
      "Iteration 400, loss = 1.2313\n",
      "Got 785 / 1275 correct (61.57) Mean absolute error: 0.52\n",
      "\n",
      "Iteration 500, loss = 1.7371\n",
      "Got 746 / 1275 correct (58.51) Mean absolute error: 0.57\n",
      "\n",
      "Got 755 / 1275 correct (59.22) Mean absolute error: 0.56\n",
      "Iteration 0, loss = 1.7860\n",
      "Got 755 / 1275 correct (59.22) Mean absolute error: 0.57\n",
      "\n",
      "Iteration 100, loss = 1.5353\n",
      "Got 846 / 1275 correct (66.35) Mean absolute error: 0.44\n",
      "\n",
      "Iteration 200, loss = 1.0043\n",
      "Got 828 / 1275 correct (64.94) Mean absolute error: 0.45\n",
      "\n",
      "Iteration 300, loss = 1.1771\n",
      "Got 800 / 1275 correct (62.75) Mean absolute error: 0.49\n",
      "\n",
      "Iteration 400, loss = 1.1328\n",
      "Got 868 / 1275 correct (68.08) Mean absolute error: 0.40\n",
      "\n",
      "Iteration 500, loss = 1.3827\n",
      "Got 894 / 1275 correct (70.12) Mean absolute error: 0.37\n",
      "\n",
      "Got 880 / 1275 correct (69.02) Mean absolute error: 0.38\n",
      "Iteration 0, loss = 1.6940\n",
      "Got 877 / 1275 correct (68.78) Mean absolute error: 0.38\n",
      "\n",
      "Iteration 100, loss = 1.6791\n",
      "Got 861 / 1275 correct (67.53) Mean absolute error: 0.42\n",
      "\n",
      "Iteration 200, loss = 1.0678\n",
      "Got 867 / 1275 correct (68.00) Mean absolute error: 0.44\n",
      "\n",
      "Iteration 300, loss = 1.1649\n",
      "Got 867 / 1275 correct (68.00) Mean absolute error: 0.44\n",
      "\n",
      "Iteration 400, loss = 1.1320\n",
      "Got 900 / 1275 correct (70.59) Mean absolute error: 0.38\n",
      "\n",
      "Iteration 500, loss = 1.3271\n",
      "Got 920 / 1275 correct (72.16) Mean absolute error: 0.35\n",
      "\n",
      "Got 919 / 1275 correct (72.08) Mean absolute error: 0.35\n",
      "Iteration 0, loss = 1.3233\n",
      "Got 918 / 1275 correct (72.00) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 100, loss = 1.3196\n",
      "Got 926 / 1275 correct (72.63) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 200, loss = 0.9600\n",
      "Got 948 / 1275 correct (74.35) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 300, loss = 1.1380\n",
      "Got 907 / 1275 correct (71.14) Mean absolute error: 0.37\n",
      "\n",
      "Iteration 400, loss = 1.1014\n",
      "Got 906 / 1275 correct (71.06) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 500, loss = 1.5409\n",
      "Got 890 / 1275 correct (69.80) Mean absolute error: 0.38\n",
      "\n",
      "Got 868 / 1275 correct (68.08) Mean absolute error: 0.40\n",
      "Iteration 0, loss = 1.5214\n",
      "Got 867 / 1275 correct (68.00) Mean absolute error: 0.40\n",
      "\n",
      "Iteration 100, loss = 1.3162\n",
      "Got 893 / 1275 correct (70.04) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 200, loss = 0.9618\n",
      "Got 920 / 1275 correct (72.16) Mean absolute error: 0.37\n",
      "\n",
      "Iteration 300, loss = 1.0913\n",
      "Got 920 / 1275 correct (72.16) Mean absolute error: 0.37\n",
      "\n",
      "Iteration 400, loss = 1.0537\n",
      "Got 939 / 1275 correct (73.65) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 500, loss = 1.3103\n",
      "Got 923 / 1275 correct (72.39) Mean absolute error: 0.37\n",
      "\n",
      "Got 938 / 1275 correct (73.57) Mean absolute error: 0.35\n",
      "Iteration 0, loss = 2.4179\n",
      "Got 938 / 1275 correct (73.57) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 100, loss = 1.2388\n",
      "Got 927 / 1275 correct (72.71) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 200, loss = 0.9054\n",
      "Got 970 / 1275 correct (76.08) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 300, loss = 1.0711\n",
      "Got 962 / 1275 correct (75.45) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 400, loss = 1.0376\n",
      "Got 936 / 1275 correct (73.41) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 500, loss = 1.2353\n",
      "Got 963 / 1275 correct (75.53) Mean absolute error: 0.31\n",
      "\n",
      "Got 950 / 1275 correct (74.51) Mean absolute error: 0.32\n",
      "Iteration 0, loss = 1.2829\n",
      "Got 948 / 1275 correct (74.35) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 100, loss = 1.2250\n",
      "Got 935 / 1275 correct (73.33) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 200, loss = 0.8884\n",
      "Got 948 / 1275 correct (74.35) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 300, loss = 1.0438\n",
      "Got 928 / 1275 correct (72.78) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 400, loss = 1.0212\n",
      "Got 948 / 1275 correct (74.35) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 500, loss = 1.3216\n",
      "Got 960 / 1275 correct (75.29) Mean absolute error: 0.33\n",
      "\n",
      "Got 977 / 1275 correct (76.63) Mean absolute error: 0.31\n",
      "Iteration 0, loss = 3.3627\n",
      "Got 969 / 1275 correct (76.00) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 100, loss = 1.2519\n",
      "Got 954 / 1275 correct (74.82) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 200, loss = 0.8837\n",
      "Got 958 / 1275 correct (75.14) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 300, loss = 1.0476\n",
      "Got 913 / 1275 correct (71.61) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 400, loss = 1.0088\n",
      "Got 936 / 1275 correct (73.41) Mean absolute error: 0.34\n",
      "\n",
      "Iteration 500, loss = 1.1799\n",
      "Got 965 / 1275 correct (75.69) Mean absolute error: 0.32\n",
      "\n",
      "Got 965 / 1275 correct (75.69) Mean absolute error: 0.32\n",
      "Iteration 0, loss = 1.7839\n",
      "Got 962 / 1275 correct (75.45) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 100, loss = 1.1401\n",
      "Got 931 / 1275 correct (73.02) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 200, loss = 0.8855\n",
      "Got 769 / 1275 correct (60.31) Mean absolute error: 0.55\n",
      "\n",
      "Iteration 300, loss = 1.0881\n",
      "Got 842 / 1275 correct (66.04) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 400, loss = 1.0542\n",
      "Got 899 / 1275 correct (70.51) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 500, loss = 1.2597\n",
      "Got 904 / 1275 correct (70.90) Mean absolute error: 0.37\n",
      "\n",
      "Got 908 / 1275 correct (71.22) Mean absolute error: 0.36\n",
      "Iteration 0, loss = 1.3557\n",
      "Got 904 / 1275 correct (70.90) Mean absolute error: 0.37\n",
      "\n",
      "Iteration 100, loss = 1.4376\n",
      "Got 855 / 1275 correct (67.06) Mean absolute error: 0.41\n",
      "\n",
      "Iteration 200, loss = 0.8437\n",
      "Got 903 / 1275 correct (70.82) Mean absolute error: 0.41\n",
      "\n",
      "Iteration 300, loss = 1.0980\n",
      "Got 886 / 1275 correct (69.49) Mean absolute error: 0.43\n",
      "\n",
      "Iteration 400, loss = 1.1844\n",
      "Got 869 / 1275 correct (68.16) Mean absolute error: 0.47\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500, loss = 1.2188\n",
      "Got 926 / 1275 correct (72.63) Mean absolute error: 0.36\n",
      "\n",
      "Got 918 / 1275 correct (72.00) Mean absolute error: 0.36\n",
      "Iteration 0, loss = 1.2721\n",
      "Got 921 / 1275 correct (72.24) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 100, loss = 1.2464\n",
      "Got 867 / 1275 correct (68.00) Mean absolute error: 0.44\n",
      "\n",
      "Iteration 200, loss = 0.8259\n",
      "Got 893 / 1275 correct (70.04) Mean absolute error: 0.40\n",
      "\n",
      "Iteration 300, loss = 0.9995\n",
      "Got 894 / 1275 correct (70.12) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 400, loss = 0.9346\n",
      "Got 962 / 1275 correct (75.45) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 500, loss = 1.1435\n",
      "Got 932 / 1275 correct (73.10) Mean absolute error: 0.35\n",
      "\n",
      "Got 906 / 1275 correct (71.06) Mean absolute error: 0.39\n",
      "Iteration 0, loss = 1.1231\n",
      "Got 907 / 1275 correct (71.14) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 100, loss = 1.2238\n",
      "Got 799 / 1275 correct (62.67) Mean absolute error: 0.51\n",
      "\n",
      "Iteration 200, loss = 1.2178\n",
      "Got 864 / 1275 correct (67.76) Mean absolute error: 0.41\n",
      "\n",
      "Iteration 300, loss = 0.9964\n",
      "Got 858 / 1275 correct (67.29) Mean absolute error: 0.46\n",
      "\n",
      "Iteration 400, loss = 0.9281\n",
      "Got 909 / 1275 correct (71.29) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 500, loss = 1.0743\n",
      "Got 894 / 1275 correct (70.12) Mean absolute error: 0.41\n",
      "\n",
      "Got 860 / 1275 correct (67.45) Mean absolute error: 0.47\n",
      "Iteration 0, loss = 1.5803\n",
      "Got 862 / 1275 correct (67.61) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 100, loss = 1.4244\n",
      "Got 889 / 1275 correct (69.73) Mean absolute error: 0.43\n",
      "\n",
      "Iteration 200, loss = 0.8294\n",
      "Got 901 / 1275 correct (70.67) Mean absolute error: 0.40\n",
      "\n",
      "Iteration 300, loss = 0.9369\n",
      "Got 893 / 1275 correct (70.04) Mean absolute error: 0.40\n",
      "\n",
      "Iteration 400, loss = 0.9276\n",
      "Got 952 / 1275 correct (74.67) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 500, loss = 1.4081\n",
      "Got 959 / 1275 correct (75.22) Mean absolute error: 0.31\n",
      "\n",
      "Got 944 / 1275 correct (74.04) Mean absolute error: 0.33\n",
      "Iteration 0, loss = 2.0294\n",
      "Got 943 / 1275 correct (73.96) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 100, loss = 1.0935\n",
      "Got 956 / 1275 correct (74.98) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 200, loss = 0.7825\n",
      "Got 972 / 1275 correct (76.24) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 300, loss = 0.9038\n",
      "Got 971 / 1275 correct (76.16) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 400, loss = 0.9228\n",
      "Got 985 / 1275 correct (77.25) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 500, loss = 1.0349\n",
      "Got 1008 / 1275 correct (79.06) Mean absolute error: 0.26\n",
      "\n",
      "Got 998 / 1275 correct (78.27) Mean absolute error: 0.27\n",
      "Iteration 0, loss = 1.0466\n",
      "Got 996 / 1275 correct (78.12) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 100, loss = 1.0541\n",
      "Got 987 / 1275 correct (77.41) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 200, loss = 0.7645\n",
      "Got 1008 / 1275 correct (79.06) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 300, loss = 0.8811\n",
      "Got 988 / 1275 correct (77.49) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 400, loss = 0.9415\n",
      "Got 999 / 1275 correct (78.35) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 500, loss = 1.0386\n",
      "Got 1004 / 1275 correct (78.75) Mean absolute error: 0.26\n",
      "\n",
      "Got 1008 / 1275 correct (79.06) Mean absolute error: 0.26\n",
      "Iteration 0, loss = 1.1087\n",
      "Got 1003 / 1275 correct (78.67) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 100, loss = 1.0126\n",
      "Got 1003 / 1275 correct (78.67) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 200, loss = 0.7476\n",
      "Got 989 / 1275 correct (77.57) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 300, loss = 0.8685\n",
      "Got 996 / 1275 correct (78.12) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 400, loss = 0.8736\n",
      "Got 995 / 1275 correct (78.04) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 500, loss = 1.0031\n",
      "Got 1013 / 1275 correct (79.45) Mean absolute error: 0.27\n",
      "\n",
      "Got 995 / 1275 correct (78.04) Mean absolute error: 0.29\n",
      "Iteration 0, loss = 1.1660\n",
      "Got 1002 / 1275 correct (78.59) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 100, loss = 1.0508\n",
      "Got 978 / 1275 correct (76.71) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 200, loss = 0.7494\n",
      "Got 980 / 1275 correct (76.86) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 300, loss = 0.8518\n",
      "Got 980 / 1275 correct (76.86) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 400, loss = 0.8701\n",
      "Got 992 / 1275 correct (77.80) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 500, loss = 1.0570\n",
      "Got 999 / 1275 correct (78.35) Mean absolute error: 0.28\n",
      "\n",
      "Got 1003 / 1275 correct (78.67) Mean absolute error: 0.27\n",
      "Iteration 0, loss = 1.0195\n",
      "Got 1001 / 1275 correct (78.51) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 100, loss = 1.0041\n",
      "Got 999 / 1275 correct (78.35) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 200, loss = 0.7172\n",
      "Got 999 / 1275 correct (78.35) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 300, loss = 0.8469\n",
      "Got 978 / 1275 correct (76.71) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 400, loss = 0.8538\n",
      "Got 1002 / 1275 correct (78.59) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 500, loss = 0.9853\n",
      "Got 1015 / 1275 correct (79.61) Mean absolute error: 0.26\n",
      "\n",
      "Got 1018 / 1275 correct (79.84) Mean absolute error: 0.26\n",
      "Iteration 0, loss = 2.2689\n",
      "Got 1016 / 1275 correct (79.69) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 100, loss = 1.0444\n",
      "Got 989 / 1275 correct (77.57) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 200, loss = 0.7087\n",
      "Got 990 / 1275 correct (77.65) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 300, loss = 0.8413\n",
      "Got 954 / 1275 correct (74.82) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 400, loss = 0.8536\n",
      "Got 922 / 1275 correct (72.31) Mean absolute error: 0.41\n",
      "\n",
      "Iteration 500, loss = 1.4921\n",
      "Got 834 / 1275 correct (65.41) Mean absolute error: 0.46\n",
      "\n",
      "Got 829 / 1275 correct (65.02) Mean absolute error: 0.46\n",
      "Iteration 0, loss = 1.7346\n",
      "Got 828 / 1275 correct (64.94) Mean absolute error: 0.47\n",
      "\n",
      "Iteration 100, loss = 1.0514\n",
      "Got 893 / 1275 correct (70.04) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 200, loss = 0.7350\n",
      "Got 873 / 1275 correct (68.47) Mean absolute error: 0.46\n",
      "\n",
      "Iteration 300, loss = 0.8419\n",
      "Got 931 / 1275 correct (73.02) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 400, loss = 0.8618\n",
      "Got 950 / 1275 correct (74.51) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 500, loss = 1.0144\n",
      "Got 953 / 1275 correct (74.75) Mean absolute error: 0.32\n",
      "\n",
      "Got 936 / 1275 correct (73.41) Mean absolute error: 0.35\n",
      "Iteration 0, loss = 0.9717\n",
      "Got 941 / 1275 correct (73.80) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 100, loss = 1.0476\n",
      "Got 930 / 1275 correct (72.94) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 200, loss = 0.6956\n",
      "Got 981 / 1275 correct (76.94) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 300, loss = 0.8027\n",
      "Got 972 / 1275 correct (76.24) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 400, loss = 0.8143\n",
      "Got 1020 / 1275 correct (80.00) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 500, loss = 0.9362\n",
      "Got 1019 / 1275 correct (79.92) Mean absolute error: 0.27\n",
      "\n",
      "Got 1020 / 1275 correct (80.00) Mean absolute error: 0.26\n",
      "Iteration 0, loss = 0.9510\n",
      "Got 1019 / 1275 correct (79.92) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 100, loss = 0.9338\n",
      "Got 979 / 1275 correct (76.78) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 200, loss = 0.6847\n",
      "Got 998 / 1275 correct (78.27) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 300, loss = 0.8148\n",
      "Got 938 / 1275 correct (73.57) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 400, loss = 0.8514\n",
      "Got 946 / 1275 correct (74.20) Mean absolute error: 0.37\n",
      "\n",
      "Iteration 500, loss = 0.9539\n",
      "Got 1000 / 1275 correct (78.43) Mean absolute error: 0.28\n",
      "\n",
      "Got 1000 / 1275 correct (78.43) Mean absolute error: 0.28\n",
      "Iteration 0, loss = 1.0367\n",
      "Got 1001 / 1275 correct (78.51) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 100, loss = 1.0965\n",
      "Got 952 / 1275 correct (74.67) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 200, loss = 0.6766\n",
      "Got 995 / 1275 correct (78.04) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 300, loss = 0.7914\n",
      "Got 998 / 1275 correct (78.27) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 400, loss = 0.7881\n",
      "Got 1016 / 1275 correct (79.69) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 500, loss = 0.9281\n",
      "Got 1003 / 1275 correct (78.67) Mean absolute error: 0.28\n",
      "\n",
      "Got 1012 / 1275 correct (79.37) Mean absolute error: 0.27\n",
      "Iteration 0, loss = 0.9274\n",
      "Got 1010 / 1275 correct (79.22) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 100, loss = 1.0698\n",
      "Got 981 / 1275 correct (76.94) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 200, loss = 0.6831\n",
      "Got 995 / 1275 correct (78.04) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 300, loss = 0.7724\n",
      "Got 1006 / 1275 correct (78.90) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 400, loss = 0.7756\n",
      "Got 984 / 1275 correct (77.18) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 500, loss = 0.8836\n",
      "Got 1002 / 1275 correct (78.59) Mean absolute error: 0.28\n",
      "\n",
      "Got 1006 / 1275 correct (78.90) Mean absolute error: 0.27\n",
      "Iteration 0, loss = 0.9128\n",
      "Got 1005 / 1275 correct (78.82) Mean absolute error: 0.28\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, loss = 0.8805\n",
      "Got 1001 / 1275 correct (78.51) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 200, loss = 0.6529\n",
      "Got 990 / 1275 correct (77.65) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 300, loss = 0.8518\n",
      "Got 957 / 1275 correct (75.06) Mean absolute error: 0.34\n",
      "\n",
      "Iteration 400, loss = 0.7587\n",
      "Got 1010 / 1275 correct (79.22) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 500, loss = 0.9408\n",
      "Got 998 / 1275 correct (78.27) Mean absolute error: 0.29\n",
      "\n",
      "Got 1002 / 1275 correct (78.59) Mean absolute error: 0.29\n",
      "Iteration 0, loss = 0.9931\n",
      "Got 996 / 1275 correct (78.12) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 100, loss = 0.9400\n",
      "Got 950 / 1275 correct (74.51) Mean absolute error: 0.38\n",
      "\n",
      "Iteration 200, loss = 0.6979\n",
      "Got 952 / 1275 correct (74.67) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 300, loss = 0.8326\n",
      "Got 916 / 1275 correct (71.84) Mean absolute error: 0.42\n",
      "\n",
      "Iteration 400, loss = 0.7577\n",
      "Got 936 / 1275 correct (73.41) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 500, loss = 1.2779\n",
      "Got 910 / 1275 correct (71.37) Mean absolute error: 0.38\n",
      "\n",
      "Got 874 / 1275 correct (68.55) Mean absolute error: 0.41\n",
      "Iteration 0, loss = 1.2601\n",
      "Got 872 / 1275 correct (68.39) Mean absolute error: 0.41\n",
      "\n",
      "Iteration 100, loss = 0.9205\n",
      "Got 958 / 1275 correct (75.14) Mean absolute error: 0.34\n",
      "\n",
      "Iteration 200, loss = 0.6985\n",
      "Got 932 / 1275 correct (73.10) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 300, loss = 0.7421\n",
      "Got 993 / 1275 correct (77.88) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 400, loss = 0.7498\n",
      "Got 1021 / 1275 correct (80.08) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 500, loss = 0.9004\n",
      "Got 1016 / 1275 correct (79.69) Mean absolute error: 0.26\n",
      "\n",
      "Got 1027 / 1275 correct (80.55) Mean absolute error: 0.25\n",
      "Iteration 0, loss = 1.4910\n",
      "Got 1028 / 1275 correct (80.63) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 100, loss = 0.8834\n",
      "Got 1017 / 1275 correct (79.76) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 200, loss = 0.6261\n",
      "Got 1008 / 1275 correct (79.06) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 300, loss = 0.7255\n",
      "Got 1027 / 1275 correct (80.55) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 400, loss = 0.7290\n",
      "Got 1037 / 1275 correct (81.33) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 500, loss = 0.8746\n",
      "Got 1035 / 1275 correct (81.18) Mean absolute error: 0.24\n",
      "\n",
      "Got 1035 / 1275 correct (81.18) Mean absolute error: 0.25\n",
      "Iteration 0, loss = 1.1255\n",
      "Got 1039 / 1275 correct (81.49) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 100, loss = 0.8515\n",
      "Got 1032 / 1275 correct (80.94) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 200, loss = 0.6087\n",
      "Got 1016 / 1275 correct (79.69) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 300, loss = 0.7147\n",
      "Got 1020 / 1275 correct (80.00) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 400, loss = 0.7154\n",
      "Got 1029 / 1275 correct (80.71) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 500, loss = 0.8211\n",
      "Got 1028 / 1275 correct (80.63) Mean absolute error: 0.25\n",
      "\n",
      "Got 1039 / 1275 correct (81.49) Mean absolute error: 0.24\n",
      "Iteration 0, loss = 0.8685\n",
      "Got 1038 / 1275 correct (81.41) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 100, loss = 0.9391\n",
      "Got 1021 / 1275 correct (80.08) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 200, loss = 0.6054\n",
      "Got 982 / 1275 correct (77.02) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 300, loss = 0.7369\n",
      "Got 979 / 1275 correct (76.78) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 400, loss = 0.7091\n",
      "Got 969 / 1275 correct (76.00) Mean absolute error: 0.34\n",
      "\n",
      "Iteration 500, loss = 0.9507\n",
      "Got 955 / 1275 correct (74.90) Mean absolute error: 0.37\n",
      "\n",
      "Got 958 / 1275 correct (75.14) Mean absolute error: 0.36\n",
      "Iteration 0, loss = 2.9625\n",
      "Got 958 / 1275 correct (75.14) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 100, loss = 1.3948\n",
      "Got 902 / 1275 correct (70.75) Mean absolute error: 0.42\n",
      "\n",
      "Iteration 200, loss = 0.6462\n",
      "Got 859 / 1275 correct (67.37) Mean absolute error: 0.50\n",
      "\n",
      "Iteration 300, loss = 0.7173\n",
      "Got 871 / 1275 correct (68.31) Mean absolute error: 0.42\n",
      "\n",
      "Iteration 400, loss = 0.7154\n",
      "Got 943 / 1275 correct (73.96) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 500, loss = 1.0199\n",
      "Got 940 / 1275 correct (73.73) Mean absolute error: 0.36\n",
      "\n",
      "Got 952 / 1275 correct (74.67) Mean absolute error: 0.35\n",
      "Iteration 0, loss = 1.7520\n",
      "Got 954 / 1275 correct (74.82) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 100, loss = 0.8614\n",
      "Got 992 / 1275 correct (77.80) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 200, loss = 0.6240\n",
      "Got 977 / 1275 correct (76.63) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 300, loss = 0.7200\n",
      "Got 990 / 1275 correct (77.65) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 400, loss = 0.7292\n",
      "Got 1005 / 1275 correct (78.82) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 500, loss = 0.9661\n",
      "Got 1019 / 1275 correct (79.92) Mean absolute error: 0.26\n",
      "\n",
      "Got 1019 / 1275 correct (79.92) Mean absolute error: 0.26\n",
      "Iteration 0, loss = 1.2694\n",
      "Got 1022 / 1275 correct (80.16) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 100, loss = 0.8250\n",
      "Got 1023 / 1275 correct (80.24) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 200, loss = 0.5896\n",
      "Got 1006 / 1275 correct (78.90) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 300, loss = 0.6774\n",
      "Got 1044 / 1275 correct (81.88) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 400, loss = 0.7007\n",
      "Got 1033 / 1275 correct (81.02) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 500, loss = 0.7960\n",
      "Got 1041 / 1275 correct (81.65) Mean absolute error: 0.23\n",
      "\n",
      "Got 1043 / 1275 correct (81.80) Mean absolute error: 0.23\n",
      "Iteration 0, loss = 1.3668\n",
      "Got 1045 / 1275 correct (81.96) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 100, loss = 0.8092\n",
      "Got 1053 / 1275 correct (82.59) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 200, loss = 0.5762\n",
      "Got 1037 / 1275 correct (81.33) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 300, loss = 0.6780\n",
      "Got 1046 / 1275 correct (82.04) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 400, loss = 0.6787\n",
      "Got 1054 / 1275 correct (82.67) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 500, loss = 0.7934\n",
      "Got 1052 / 1275 correct (82.51) Mean absolute error: 0.23\n",
      "\n",
      "Got 1056 / 1275 correct (82.82) Mean absolute error: 0.22\n",
      "Iteration 0, loss = 0.8023\n",
      "Got 1056 / 1275 correct (82.82) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 100, loss = 0.7872\n",
      "Got 1065 / 1275 correct (83.53) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 200, loss = 0.5735\n",
      "Got 1035 / 1275 correct (81.18) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 300, loss = 0.6583\n",
      "Got 1045 / 1275 correct (81.96) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 400, loss = 0.6763\n",
      "Got 1060 / 1275 correct (83.14) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 500, loss = 0.7632\n",
      "Got 1054 / 1275 correct (82.67) Mean absolute error: 0.22\n",
      "\n",
      "Got 1062 / 1275 correct (83.29) Mean absolute error: 0.21\n",
      "Iteration 0, loss = 0.7824\n",
      "Got 1065 / 1275 correct (83.53) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 100, loss = 0.7852\n",
      "Got 1043 / 1275 correct (81.80) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 200, loss = 0.5577\n",
      "Got 1029 / 1275 correct (80.71) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 300, loss = 0.6661\n",
      "Got 1028 / 1275 correct (80.63) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 400, loss = 0.6648\n",
      "Got 1043 / 1275 correct (81.80) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 500, loss = 0.7677\n",
      "Got 1043 / 1275 correct (81.80) Mean absolute error: 0.24\n",
      "\n",
      "Got 1026 / 1275 correct (80.47) Mean absolute error: 0.27\n",
      "Iteration 0, loss = 0.9963\n",
      "Got 1029 / 1275 correct (80.71) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 100, loss = 0.8089\n",
      "Got 983 / 1275 correct (77.10) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 200, loss = 0.5491\n",
      "Got 1028 / 1275 correct (80.63) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 300, loss = 0.6701\n",
      "Got 1013 / 1275 correct (79.45) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 400, loss = 0.6493\n",
      "Got 1035 / 1275 correct (81.18) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 500, loss = 0.7953\n",
      "Got 991 / 1275 correct (77.73) Mean absolute error: 0.29\n",
      "\n",
      "Got 988 / 1275 correct (77.49) Mean absolute error: 0.29\n",
      "Iteration 0, loss = 0.7947\n",
      "Got 985 / 1275 correct (77.25) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 100, loss = 0.7859\n",
      "Got 1024 / 1275 correct (80.31) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 200, loss = 0.5656\n",
      "Got 988 / 1275 correct (77.49) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 300, loss = 0.6427\n",
      "Got 980 / 1275 correct (76.86) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 400, loss = 0.6473\n",
      "Got 997 / 1275 correct (78.20) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 500, loss = 1.0558\n",
      "Got 969 / 1275 correct (76.00) Mean absolute error: 0.32\n",
      "\n",
      "Got 970 / 1275 correct (76.08) Mean absolute error: 0.31\n",
      "Iteration 0, loss = 0.9342\n",
      "Got 964 / 1275 correct (75.61) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 100, loss = 0.9750\n",
      "Got 976 / 1275 correct (76.55) Mean absolute error: 0.32\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200, loss = 0.5548\n",
      "Got 923 / 1275 correct (72.39) Mean absolute error: 0.37\n",
      "\n",
      "Iteration 300, loss = 0.6999\n",
      "Got 923 / 1275 correct (72.39) Mean absolute error: 0.39\n",
      "\n",
      "Iteration 400, loss = 0.6860\n",
      "Got 934 / 1275 correct (73.25) Mean absolute error: 0.38\n",
      "\n",
      "Iteration 500, loss = 0.8746\n",
      "Got 968 / 1275 correct (75.92) Mean absolute error: 0.36\n",
      "\n",
      "Got 929 / 1275 correct (72.86) Mean absolute error: 0.41\n",
      "Iteration 0, loss = 2.7452\n",
      "Got 949 / 1275 correct (74.43) Mean absolute error: 0.38\n",
      "\n",
      "Iteration 100, loss = 0.8758\n",
      "Got 948 / 1275 correct (74.35) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 200, loss = 0.5462\n",
      "Got 904 / 1275 correct (70.90) Mean absolute error: 0.41\n",
      "\n",
      "Iteration 300, loss = 0.6320\n",
      "Got 951 / 1275 correct (74.59) Mean absolute error: 0.34\n",
      "\n",
      "Iteration 400, loss = 0.7037\n",
      "Got 969 / 1275 correct (76.00) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 500, loss = 1.2048\n",
      "Got 960 / 1275 correct (75.29) Mean absolute error: 0.32\n",
      "\n",
      "Got 959 / 1275 correct (75.22) Mean absolute error: 0.32\n",
      "Iteration 0, loss = 0.8311\n",
      "Got 958 / 1275 correct (75.14) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 100, loss = 0.7668\n",
      "Got 982 / 1275 correct (77.02) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 200, loss = 0.5351\n",
      "Got 989 / 1275 correct (77.57) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 300, loss = 0.6194\n",
      "Got 1016 / 1275 correct (79.69) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 400, loss = 0.6445\n",
      "Got 1026 / 1275 correct (80.47) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 500, loss = 0.7905\n",
      "Got 1023 / 1275 correct (80.24) Mean absolute error: 0.25\n",
      "\n",
      "Got 1025 / 1275 correct (80.39) Mean absolute error: 0.25\n",
      "Iteration 0, loss = 0.7316\n",
      "Got 1023 / 1275 correct (80.24) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 100, loss = 0.7431\n",
      "Got 1038 / 1275 correct (81.41) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 200, loss = 0.5174\n",
      "Got 1044 / 1275 correct (81.88) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 300, loss = 0.6110\n",
      "Got 1045 / 1275 correct (81.96) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 400, loss = 0.6352\n",
      "Got 1071 / 1275 correct (84.00) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 500, loss = 0.8685\n",
      "Got 1054 / 1275 correct (82.67) Mean absolute error: 0.22\n",
      "\n",
      "Got 1051 / 1275 correct (82.43) Mean absolute error: 0.22\n",
      "Iteration 0, loss = 0.7262\n",
      "Got 1053 / 1275 correct (82.59) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 100, loss = 0.7402\n",
      "Got 1059 / 1275 correct (83.06) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 200, loss = 0.5189\n",
      "Got 1044 / 1275 correct (81.88) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 300, loss = 0.6020\n",
      "Got 1049 / 1275 correct (82.27) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 400, loss = 0.6110\n",
      "Got 1066 / 1275 correct (83.61) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 500, loss = 0.7372\n",
      "Got 1061 / 1275 correct (83.22) Mean absolute error: 0.22\n",
      "\n",
      "Got 1058 / 1275 correct (82.98) Mean absolute error: 0.22\n",
      "Iteration 0, loss = 0.7169\n",
      "Got 1054 / 1275 correct (82.67) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 100, loss = 0.7312\n",
      "Got 1054 / 1275 correct (82.67) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 200, loss = 0.5126\n",
      "Got 1035 / 1275 correct (81.18) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 300, loss = 0.6034\n",
      "Got 1046 / 1275 correct (82.04) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 400, loss = 0.6147\n",
      "Got 1065 / 1275 correct (83.53) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 500, loss = 0.7061\n",
      "Got 1052 / 1275 correct (82.51) Mean absolute error: 0.23\n",
      "\n",
      "Got 1054 / 1275 correct (82.67) Mean absolute error: 0.22\n",
      "Iteration 0, loss = 1.0146\n",
      "Got 1055 / 1275 correct (82.75) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 100, loss = 0.7208\n",
      "Got 1035 / 1275 correct (81.18) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 200, loss = 0.5118\n",
      "Got 1024 / 1275 correct (80.31) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 300, loss = 0.5907\n",
      "Got 1014 / 1275 correct (79.53) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 400, loss = 0.6499\n",
      "Got 1037 / 1275 correct (81.33) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 500, loss = 0.7280\n",
      "Got 1039 / 1275 correct (81.49) Mean absolute error: 0.24\n",
      "\n",
      "Got 1045 / 1275 correct (81.96) Mean absolute error: 0.23\n",
      "Iteration 0, loss = 0.7174\n",
      "Got 1045 / 1275 correct (81.96) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 100, loss = 0.7380\n",
      "Got 1051 / 1275 correct (82.43) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 200, loss = 0.5006\n",
      "Got 1027 / 1275 correct (80.55) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 300, loss = 0.6239\n",
      "Got 996 / 1275 correct (78.12) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 400, loss = 0.6185\n",
      "Got 958 / 1275 correct (75.14) Mean absolute error: 0.38\n",
      "\n",
      "Iteration 500, loss = 0.7655\n",
      "Got 958 / 1275 correct (75.14) Mean absolute error: 0.32\n",
      "\n",
      "Got 967 / 1275 correct (75.84) Mean absolute error: 0.32\n",
      "Iteration 0, loss = 0.9387\n",
      "Got 971 / 1275 correct (76.16) Mean absolute error: 0.31\n",
      "\n",
      "Iteration 100, loss = 0.8341\n",
      "Got 991 / 1275 correct (77.73) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 200, loss = 0.5364\n",
      "Got 987 / 1275 correct (77.41) Mean absolute error: 0.34\n",
      "\n",
      "Iteration 300, loss = 0.5940\n",
      "Got 985 / 1275 correct (77.25) Mean absolute error: 0.32\n",
      "\n",
      "Iteration 400, loss = 0.6792\n",
      "Got 985 / 1275 correct (77.25) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 500, loss = 0.8847\n",
      "Got 1024 / 1275 correct (80.31) Mean absolute error: 0.28\n",
      "\n",
      "Got 1027 / 1275 correct (80.55) Mean absolute error: 0.27\n",
      "Iteration 0, loss = 2.8242\n",
      "Got 1028 / 1275 correct (80.63) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 100, loss = 0.9171\n",
      "Got 1025 / 1275 correct (80.39) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 200, loss = 0.5002\n",
      "Got 997 / 1275 correct (78.20) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 300, loss = 0.6061\n",
      "Got 995 / 1275 correct (78.04) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 400, loss = 0.6015\n",
      "Got 990 / 1275 correct (77.65) Mean absolute error: 0.30\n",
      "\n",
      "Iteration 500, loss = 0.6869\n",
      "Got 1031 / 1275 correct (80.86) Mean absolute error: 0.24\n",
      "\n",
      "Got 1025 / 1275 correct (80.39) Mean absolute error: 0.25\n",
      "Iteration 0, loss = 0.7061\n",
      "Got 1028 / 1275 correct (80.63) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 100, loss = 0.7085\n",
      "Got 1031 / 1275 correct (80.86) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 200, loss = 0.5530\n",
      "Got 1026 / 1275 correct (80.47) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 300, loss = 0.5814\n",
      "Got 1042 / 1275 correct (81.73) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 400, loss = 0.5861\n",
      "Got 1047 / 1275 correct (82.12) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 500, loss = 0.7624\n",
      "Got 1053 / 1275 correct (82.59) Mean absolute error: 0.21\n",
      "\n",
      "Got 1059 / 1275 correct (83.06) Mean absolute error: 0.21\n",
      "Iteration 0, loss = 0.7439\n",
      "Got 1062 / 1275 correct (83.29) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 100, loss = 0.7017\n",
      "Got 1073 / 1275 correct (84.16) Mean absolute error: 0.20\n",
      "\n",
      "Iteration 200, loss = 0.4813\n",
      "Got 1049 / 1275 correct (82.27) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 300, loss = 0.5733\n",
      "Got 1028 / 1275 correct (80.63) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 400, loss = 0.5743\n",
      "Got 1053 / 1275 correct (82.59) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 500, loss = 0.7719\n",
      "Got 1056 / 1275 correct (82.82) Mean absolute error: 0.23\n",
      "\n",
      "Got 1044 / 1275 correct (81.88) Mean absolute error: 0.25\n",
      "Iteration 0, loss = 0.7403\n",
      "Got 1039 / 1275 correct (81.49) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 100, loss = 0.7074\n",
      "Got 1022 / 1275 correct (80.16) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 200, loss = 0.4988\n",
      "Got 1019 / 1275 correct (79.92) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 300, loss = 0.5474\n",
      "Got 1024 / 1275 correct (80.31) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 400, loss = 0.5708\n",
      "Got 1040 / 1275 correct (81.57) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 500, loss = 0.6755\n",
      "Got 1043 / 1275 correct (81.80) Mean absolute error: 0.25\n",
      "\n",
      "Got 1022 / 1275 correct (80.16) Mean absolute error: 0.26\n",
      "Iteration 0, loss = 0.8372\n",
      "Got 1022 / 1275 correct (80.16) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 100, loss = 0.6702\n",
      "Got 1030 / 1275 correct (80.78) Mean absolute error: 0.26\n",
      "\n",
      "Iteration 200, loss = 0.4704\n",
      "Got 1052 / 1275 correct (82.51) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 300, loss = 0.5425\n",
      "Got 1053 / 1275 correct (82.59) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 400, loss = 0.5616\n",
      "Got 1050 / 1275 correct (82.35) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 500, loss = 0.6513\n",
      "Got 1059 / 1275 correct (83.06) Mean absolute error: 0.21\n",
      "\n",
      "Got 1068 / 1275 correct (83.76) Mean absolute error: 0.21\n",
      "Iteration 0, loss = 0.6984\n",
      "Got 1068 / 1275 correct (83.76) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 100, loss = 0.6723\n",
      "Got 1064 / 1275 correct (83.45) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 200, loss = 0.4674\n",
      "Got 1048 / 1275 correct (82.20) Mean absolute error: 0.23\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 300, loss = 0.5376\n",
      "Got 1071 / 1275 correct (84.00) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 400, loss = 0.5595\n",
      "Got 1067 / 1275 correct (83.69) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 500, loss = 0.6690\n",
      "Got 1052 / 1275 correct (82.51) Mean absolute error: 0.24\n",
      "\n",
      "Got 1051 / 1275 correct (82.43) Mean absolute error: 0.24\n",
      "Iteration 0, loss = 0.6726\n",
      "Got 1054 / 1275 correct (82.67) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 100, loss = 0.6818\n",
      "Got 1050 / 1275 correct (82.35) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 200, loss = 0.4616\n",
      "Got 1052 / 1275 correct (82.51) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 300, loss = 0.5418\n",
      "Got 1044 / 1275 correct (81.88) Mean absolute error: 0.24\n",
      "\n",
      "Iteration 400, loss = 0.5638\n",
      "Got 1066 / 1275 correct (83.61) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 500, loss = 0.6683\n",
      "Got 1047 / 1275 correct (82.12) Mean absolute error: 0.23\n",
      "\n",
      "Got 1059 / 1275 correct (83.06) Mean absolute error: 0.22\n",
      "Iteration 0, loss = 0.7278\n",
      "Got 1060 / 1275 correct (83.14) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 100, loss = 0.6689\n",
      "Got 1051 / 1275 correct (82.43) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 200, loss = 0.4483\n",
      "Got 1030 / 1275 correct (80.78) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 300, loss = 0.6172\n",
      "Got 1034 / 1275 correct (81.10) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 400, loss = 0.5508\n",
      "Got 1055 / 1275 correct (82.75) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 500, loss = 0.8116\n",
      "Got 943 / 1275 correct (73.96) Mean absolute error: 0.35\n",
      "\n",
      "Got 924 / 1275 correct (72.47) Mean absolute error: 0.36\n",
      "Iteration 0, loss = 0.9326\n",
      "Got 931 / 1275 correct (73.02) Mean absolute error: 0.36\n",
      "\n",
      "Iteration 100, loss = 0.6706\n",
      "Got 1002 / 1275 correct (78.59) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 200, loss = 0.4803\n",
      "Got 1004 / 1275 correct (78.75) Mean absolute error: 0.28\n",
      "\n",
      "Iteration 300, loss = 0.5278\n",
      "Got 1016 / 1275 correct (79.69) Mean absolute error: 0.27\n",
      "\n",
      "Iteration 400, loss = 0.5494\n",
      "Got 1034 / 1275 correct (81.10) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 500, loss = 0.7775\n",
      "Got 1032 / 1275 correct (80.94) Mean absolute error: 0.25\n",
      "\n",
      "Got 1035 / 1275 correct (81.18) Mean absolute error: 0.25\n",
      "Iteration 0, loss = 0.7493\n",
      "Got 1033 / 1275 correct (81.02) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 100, loss = 0.7396\n",
      "Got 976 / 1275 correct (76.55) Mean absolute error: 0.33\n",
      "\n",
      "Iteration 200, loss = 0.4487\n",
      "Got 947 / 1275 correct (74.27) Mean absolute error: 0.43\n",
      "\n",
      "Iteration 300, loss = 0.5988\n",
      "Got 954 / 1275 correct (74.82) Mean absolute error: 0.35\n",
      "\n",
      "Iteration 400, loss = 0.5754\n",
      "Got 997 / 1275 correct (78.20) Mean absolute error: 0.29\n",
      "\n",
      "Iteration 500, loss = 0.6461\n",
      "Got 1033 / 1275 correct (81.02) Mean absolute error: 0.25\n",
      "\n",
      "Got 1033 / 1275 correct (81.02) Mean absolute error: 0.25\n",
      "Iteration 0, loss = 0.6477\n",
      "Got 1032 / 1275 correct (80.94) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 100, loss = 0.6474\n",
      "Got 1064 / 1275 correct (83.45) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 200, loss = 0.4731\n",
      "Got 1044 / 1275 correct (81.88) Mean absolute error: 0.25\n",
      "\n",
      "Iteration 300, loss = 0.5693\n",
      "Got 1062 / 1275 correct (83.29) Mean absolute error: 0.23\n",
      "\n",
      "Iteration 400, loss = 0.5340\n",
      "Got 1070 / 1275 correct (83.92) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 500, loss = 0.6849\n",
      "Got 1071 / 1275 correct (84.00) Mean absolute error: 0.21\n",
      "\n",
      "Got 1071 / 1275 correct (84.00) Mean absolute error: 0.21\n",
      "Iteration 0, loss = 0.7008\n",
      "Got 1071 / 1275 correct (84.00) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 100, loss = 0.6349\n",
      "Got 1081 / 1275 correct (84.78) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 200, loss = 0.4395\n",
      "Got 1071 / 1275 correct (84.00) Mean absolute error: 0.22\n",
      "\n",
      "Iteration 300, loss = 0.5063\n",
      "Got 1076 / 1275 correct (84.39) Mean absolute error: 0.20\n",
      "\n",
      "Iteration 400, loss = 0.5280\n",
      "Got 1094 / 1275 correct (85.80) Mean absolute error: 0.19\n",
      "\n",
      "Iteration 500, loss = 0.6224\n",
      "Got 1083 / 1275 correct (84.94) Mean absolute error: 0.20\n",
      "\n",
      "Got 1086 / 1275 correct (85.18) Mean absolute error: 0.20\n",
      "Iteration 0, loss = 0.7172\n",
      "Got 1086 / 1275 correct (85.18) Mean absolute error: 0.20\n",
      "\n",
      "Iteration 100, loss = 0.6221\n",
      "Got 1090 / 1275 correct (85.49) Mean absolute error: 0.19\n",
      "\n",
      "Iteration 200, loss = 0.4403\n",
      "Got 1063 / 1275 correct (83.37) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 300, loss = 0.5024\n",
      "Got 1068 / 1275 correct (83.76) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 400, loss = 0.5155\n",
      "Got 1088 / 1275 correct (85.33) Mean absolute error: 0.19\n",
      "\n",
      "Iteration 500, loss = 0.6153\n",
      "Got 1073 / 1275 correct (84.16) Mean absolute error: 0.21\n",
      "\n",
      "Got 1074 / 1275 correct (84.24) Mean absolute error: 0.21\n",
      "Iteration 0, loss = 0.6707\n",
      "Got 1074 / 1275 correct (84.24) Mean absolute error: 0.21\n",
      "\n",
      "Iteration 100, loss = 0.6224\n",
      "Got 1079 / 1275 correct (84.63) Mean absolute error: 0.20\n",
      "\n",
      "Iteration 200, loss = 0.4284\n",
      "Got 1082 / 1275 correct (84.86) Mean absolute error: 0.20\n",
      "\n",
      "Iteration 300, loss = 0.4975\n",
      "Got 1075 / 1275 correct (84.31) Mean absolute error: 0.21\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-27f4f26c673e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0moptimizer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mcoral_validation_accs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoral_maes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoral_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Final Acc: \\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-97abfeb9b112>\u001b[0m in \u001b[0;36mtrain_func\u001b[1;34m(model, optimizer, epochs, mode)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rodri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rodri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                    )\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rodri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\optim\\functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = None\n",
    "optimizer1 = None\n",
    "\n",
    "model1 = CoralNet(num_classes, num_features, hidden_layer_size)\n",
    "normal = 0\n",
    "# model = NormalNet(num_classes, num_features, hidden_layer_size)\n",
    "# normal = True\n",
    "\n",
    "\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)  \n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=learning_rate)  \n",
    "\n",
    "coral_validation_accs, coral_maes, coral_losses = train_func(model1, optimizer1, epochs=epics, mode=normal)\n",
    "print(\"Final Acc: \\n\")\n",
    "validate(loader_val, model1, normal)\n",
    "# np.save('pytorch_10epochs.npy', validation_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORAL: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(loader_test, model1, normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "PsYUXewlXKC-",
    "outputId": "5d03979c-de60-4a11-99fe-15c99ce9c4e6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotGD(coral_losses, model='CORAL NN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "L0BaHZoXfwd5",
    "outputId": "5ae667f5-b16a-4d72-d2f9-e4963aa9f28e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotAcc(coral_validation_accs, model='CORAL NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline NN: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mliyWanzSS6w"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = NormalNet(num_classes, num_features, hidden_layer_size)\n",
    "normal = 1\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "validation_accs, maes, losses = train_func(model, optimizer, epochs=100, mode=normal)\n",
    "print(\"Final Acc: \\n\")\n",
    "validate(loader_val, model, normal)\n",
    "# plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline NN: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(loader_test, model, normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "p-A7nTeiGxZ4",
    "outputId": "24a72fee-1ccd-428b-90d7-7deca1e5825c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1399 / 1594 correct (87.77) Mean absolute error: 0.27\n",
      "(0.8776662484316186, tensor(0.2679, device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotGD(losses, model='Baseline NN')\n",
    "plotAcc(validation_accs, model='Baseline NN')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_nets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
